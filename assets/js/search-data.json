{
  
    
        "post0": {
            "title": "TF/Keras BERT Baseline (Training/Inference)",
            "content": "This notebook shows how to train a neural network model with pre-trained BERT in Tensorflow/Keras. It is based on @xhlulu&#39;s Disaster NLP: Keras BERT using TFHub notebook and Text Extraction with BERT example at Keras. . This competition is a code competition without access to internet. So we add the transformers tokenizer and pre-trained BERT model through Kaggle Datasets instead. . Hope it helps. . Changelogs . Version CV Score Public Score Changes Comment . v9 | to be updated | to be updated | use transformers&#39; tokenizer | . v8 | 0.653635 | 0.606 | add 5-fold CV + early-stopping back. | | . v7 | N/A | 0.617 | fix the bug in learning rate scheduler | overfitting to train? (n=20) | . v6 | N/A | 0.566 | add the warm-up learning rate scheduler | With a bug. Don&#39;t use it | . v5 | N/A | 0.531 | roll back to v3 | | . v4 | N/A | 0.573 | add early-stopping | seemed to stop too early with patience=1 (n=5) | . v3 | N/A | 0.530 | initial baseline | | . Load Libraries and Data . %reload_ext autoreload %autoreload 2 %matplotlib inline . from copy import copy import joblib from matplotlib import pyplot as plt import numpy as np import os import pandas as pd from pathlib import Path import seaborn as sns from sklearn.metrics import mean_squared_error from sklearn.model_selection import KFold import sys from warnings import simplefilter import tensorflow as tf from tensorflow.keras import Model, Input from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler from tensorflow.keras.initializers import Constant from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout from tensorflow.keras.layers.experimental.preprocessing import TextVectorization from tensorflow.keras.metrics import RootMeanSquaredError from tensorflow.keras.utils import to_categorical from tensorflow.keras.optimizers import Adam from transformers import TFBertModel, BertConfig, BertTokenizerFast simplefilter(&#39;ignore&#39;) plt.style.use(&#39;fivethirtyeight&#39;) . gpu = tf.config.list_physical_devices(&#39;GPU&#39;) print(&quot;Num GPUs Available: &quot;, len(gpu)) if len(gpu) &gt; 0: tf.config.experimental.set_memory_growth(gpu[0], True) . Num GPUs Available: 1 . model_name = &#39;bert_v9&#39; data_dir = Path(&#39;../input/commonlitreadabilityprize&#39;) train_file = data_dir / &#39;train.csv&#39; test_file = data_dir / &#39;test.csv&#39; sample_file = data_dir / &#39;sample_submission.csv&#39; build_dir = Path(&#39;../build/&#39;) output_dir = build_dir / model_name trn_encoded_file = output_dir / &#39;trn.enc.joblib&#39; tokenizer_file = output_dir / &#39;tokenizer.joblib&#39; val_predict_file = output_dir / f&#39;{model_name}.val.txt&#39; submission_file = &#39;submission.csv&#39; module_url = &quot;../input/bert-en-uncased-l24-h1024-a16&quot; id_col = &#39;id&#39; target_col = &#39;target&#39; text_col = &#39;excerpt&#39; max_len = 205 n_fold = 5 n_est = 2 n_stop = 2 batch_size = 8 seed = 42 . output_dir.mkdir(parents=True, exist_ok=True) . trn = pd.read_csv(train_file, index_col=id_col) tst = pd.read_csv(test_file, index_col=id_col) y = trn[target_col].values print(trn.shape, y.shape, tst.shape) trn.head() . (2834, 5) (2834,) (7, 3) . url_legal license excerpt target standard_error . id . c12129c31 NaN | NaN | When the young people returned to the ballroom... | -0.340259 | 0.464009 | . 85aa80a4c NaN | NaN | All through dinner time, Mrs. Fayre was somewh... | -0.315372 | 0.480805 | . b69ac6792 NaN | NaN | As Roger had predicted, the snow departed as q... | -0.580118 | 0.476676 | . dd1000b26 NaN | NaN | And outside before the palace a great garden w... | -1.054013 | 0.450007 | . 37c1b32fb NaN | NaN | Once upon a time there were Three Bears who li... | 0.247197 | 0.510845 | . Tokenization Using transformers . pretrained_dir = output_dir / &quot;bert_base_uncased/&quot; pretrained_dir.mkdir(exist_ok=True) def load_tokenizer(): if not os.path.exists(pretrained_dir / &#39;vocab.txt&#39;): tokenizer = BertTokenizerFast.from_pretrained(&quot;bert-base-uncased&quot;) tokenizer.save_pretrained(pretrained_dir) else: print(&#39;loading the saved pretrained tokenizer&#39;) tokenizer = BertTokenizerFast.from_pretrained(str(pretrained_dir)) model_config = BertConfig.from_pretrained(str(pretrained_dir)) model_config.output_hidden_states = True return tokenizer, model_config def load_bert(config): if not os.path.exists(pretrained_dir / &#39;tf_model.h5&#39;): bert_model = TFBertModel.from_pretrained(&quot;bert-base-uncased&quot;, config=config) bert_model.save_pretrained(pretrained_dir) else: print(&#39;loading the saved pretrained model&#39;) bert_model = TFBertModel.from_pretrained(pretrained_dir, config=config) return bert_model . def bert_encode(texts, tokenizer, max_len=max_len): input_ids = [] token_type_ids = [] attention_mask = [] for text in texts: token = tokenizer(text, max_length=max_len, truncation=True, padding=&#39;max_length&#39;, add_special_tokens=True) input_ids.append(token[&#39;input_ids&#39;]) token_type_ids.append(token[&#39;token_type_ids&#39;]) attention_mask.append(token[&#39;attention_mask&#39;]) return np.array(input_ids), np.array(token_type_ids), np.array(attention_mask) . tokenizer, bert_config = load_tokenizer() X = bert_encode(trn[text_col].values, tokenizer, max_len=max_len) X_tst = bert_encode(tst[text_col].values, tokenizer, max_len=max_len) y = trn[target_col].values print(X[0].shape, X_tst[0].shape, y.shape) . loading the saved pretrained tokenizer (2834, 205) (7, 205) (2834,) . Save Tokenizer and Encoded Training Data . joblib.dump(X, trn_encoded_file) joblib.dump(tokenizer, tokenizer_file) . [&#39;../build/bert_v9/tokenizer.joblib&#39;] . Model Training with Cross-Validation . Simple model with only an output dense layer added to the pre-trained BERT model. . def build_model(bert_model, max_len=max_len): input_ids = Input(shape=(max_len,), dtype=tf.int32, name=&quot;input_ids&quot;) token_type_ids = Input(shape=(max_len,), dtype=tf.int32, name=&quot;token_type_ids&quot;) attention_mask = Input(shape=(max_len,), dtype=tf.int32, name=&quot;attention_mask&quot;) sequence_output = bert_model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)[0] clf_output = sequence_output[:, 0, :] clf_output = Dropout(.1)(clf_output) out = Dense(1, activation=&#39;linear&#39;)(clf_output) model = Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=out) model.compile(Adam(lr=1e-5), loss=&#39;mean_squared_error&#39;, metrics=[RootMeanSquaredError()]) return model . Training the model with early stopping and a learning-rate scheduler . def scheduler(epoch, lr, warmup=5, decay_start=10): if epoch &lt;= warmup: return lr / (warmup - epoch + 1) elif warmup &lt; epoch &lt;= decay_start: return lr else: return lr * tf.math.exp(-.1) ls = LearningRateScheduler(scheduler) es = EarlyStopping(patience=n_stop, restore_best_weights=True) cv = KFold(n_splits=n_fold, shuffle=True, random_state=seed) p = np.zeros_like(y, dtype=float) p_tst = np.zeros((X_tst[0].shape[0], ), dtype=float) for i, (i_trn, i_val) in enumerate(cv.split(X[0]), 1): print(f&#39;training CV #{i}:&#39;) tf.random.set_seed(seed + i) bert_model = load_bert(bert_config) clf = build_model(bert_model, max_len=max_len) if i == 1: print(clf.summary()) history = clf.fit([x[i_trn] for x in X], y[i_trn], validation_data=([x[i_val] for x in X], y[i_val]), epochs=n_est, batch_size=batch_size, callbacks=[ls]) clf.save_weights(f&#39;{model_name}_cv{i}.h5&#39;) p[i_val] = clf.predict([x[i_val] for x in X]).flatten() p_tst += clf.predict(X_tst).flatten() / n_fold . training CV #1: loading the saved pretrained model . All model checkpoint layers were used when initializing TFBertModel. All the layers of TFBertModel were initialized from the model checkpoint at ../build/bert_v9/bert_base_uncased. If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training. . WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. Model: &#34;model_1&#34; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_ids (InputLayer) [(None, 205)] 0 __________________________________________________________________________________________________ attention_mask (InputLayer) [(None, 205)] 0 __________________________________________________________________________________________________ token_type_ids (InputLayer) [(None, 205)] 0 __________________________________________________________________________________________________ tf_bert_model_1 (TFBertModel) TFBaseModelOutputWit 109482240 input_ids[0][0] attention_mask[0][0] token_type_ids[0][0] __________________________________________________________________________________________________ tf.__operators__.getitem_1 (Sli (None, 768) 0 tf_bert_model_1[0][13] __________________________________________________________________________________________________ dropout_75 (Dropout) (None, 768) 0 tf.__operators__.getitem_1[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 1) 769 dropout_75[0][0] ================================================================================================== Total params: 109,483,009 Trainable params: 109,483,009 Non-trainable params: 0 __________________________________________________________________________________________________ None Epoch 1/2 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_1/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_1/bert/pooler/dense/bias:0&#39;] when minimizing the loss. WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_1/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_1/bert/pooler/dense/bias:0&#39;] when minimizing the loss. 284/284 [==============================] - ETA: 0s - loss: 1.0671WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. 284/284 [==============================] - 118s 366ms/step - loss: 1.0662 - val_loss: 0.4776 Epoch 2/2 284/284 [==============================] - 104s 367ms/step - loss: 0.5244 - val_loss: 0.4544 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. training CV #2: loading the saved pretrained model . All model checkpoint layers were used when initializing TFBertModel. All the layers of TFBertModel were initialized from the model checkpoint at ../build/bert_v9/bert_base_uncased. If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training. . WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. Epoch 1/2 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_2/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_2/bert/pooler/dense/bias:0&#39;] when minimizing the loss. WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_2/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_2/bert/pooler/dense/bias:0&#39;] when minimizing the loss. 284/284 [==============================] - ETA: 0s - loss: 1.0675WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. 284/284 [==============================] - 117s 365ms/step - loss: 1.0667 - val_loss: 0.5301 Epoch 2/2 284/284 [==============================] - 101s 356ms/step - loss: 0.5712 - val_loss: 0.4714 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. training CV #3: loading the saved pretrained model . All model checkpoint layers were used when initializing TFBertModel. All the layers of TFBertModel were initialized from the model checkpoint at ../build/bert_v9/bert_base_uncased. If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training. . WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. Epoch 1/2 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_3/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_3/bert/pooler/dense/bias:0&#39;] when minimizing the loss. WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_3/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_3/bert/pooler/dense/bias:0&#39;] when minimizing the loss. 284/284 [==============================] - ETA: 0s - loss: 0.9928WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. 284/284 [==============================] - 118s 365ms/step - loss: 0.9922 - val_loss: 0.5096 Epoch 2/2 284/284 [==============================] - 102s 358ms/step - loss: 0.5822 - val_loss: 0.5252 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. training CV #4: loading the saved pretrained model . All model checkpoint layers were used when initializing TFBertModel. All the layers of TFBertModel were initialized from the model checkpoint at ../build/bert_v9/bert_base_uncased. If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training. . WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. Epoch 1/2 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_4/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_4/bert/pooler/dense/bias:0&#39;] when minimizing the loss. WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_4/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_4/bert/pooler/dense/bias:0&#39;] when minimizing the loss. 284/284 [==============================] - ETA: 0s - loss: 1.0345WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. 284/284 [==============================] - 120s 375ms/step - loss: 1.0337 - val_loss: 0.5380 Epoch 2/2 284/284 [==============================] - 102s 358ms/step - loss: 0.5264 - val_loss: 0.4960 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. training CV #5: loading the saved pretrained model . All model checkpoint layers were used when initializing TFBertModel. All the layers of TFBertModel were initialized from the model checkpoint at ../build/bert_v9/bert_base_uncased. If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training. . WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. Epoch 1/2 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_5/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_5/bert/pooler/dense/bias:0&#39;] when minimizing the loss. WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. WARNING:tensorflow:Gradients do not exist for variables [&#39;tf_bert_model_5/bert/pooler/dense/kernel:0&#39;, &#39;tf_bert_model_5/bert/pooler/dense/bias:0&#39;] when minimizing the loss. 284/284 [==============================] - ETA: 0s - loss: 1.0071WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. 284/284 [==============================] - 120s 371ms/step - loss: 1.0063 - val_loss: 0.5089 Epoch 2/2 284/284 [==============================] - 103s 363ms/step - loss: 0.4906 - val_loss: 0.5032 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained(&#39;name&#39;, output_attentions=True)`). WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`. . Print CV RMSE and Save CV Predictions . print(f&#39;CV RMSE: {mean_squared_error(y, p, squared=False):.6f}&#39;) np.savetxt(val_predict_file, p, fmt=&#39;%.6f&#39;) . Submission . sub = pd.read_csv(sample_file, index_col=id_col) sub[target_col] = p_tst sub.to_csv(submission_file) sub.head() .",
            "url": "kaggler.com/notebook/kaggle/nlp/2021/05/07/tf-keras-bert-baseline-training-inference.html",
            "relUrl": "/notebook/kaggle/nlp/2021/05/07/tf-keras-bert-baseline-training-inference.html",
            "date": " • May 7, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "PyTorch Lightning RoBERTa Baseline (Training/Inference)",
            "content": "This notebook shows how to train a neural network model with pre-trained RoBERTa in Pytorch Lightning. . This competition is a code competition without access to internet. So we add the pretrained model through @abhishek&#39;s roberta-base Kaggle Datasets instead. . This notebook shares the same structure as in TF/Keras BERT Baseline (Training/Inference), and is built on top of two other notebooks: . BERT &amp; PyTorch [CommonLit Readability] Simple by @shivanandmn | RoBERTa meets TPUs by @yassinealouini | . Hope it helps. . Changelogs . Version CV Score Public Score Changes Comment . v1 | | to be updated | initial baseline | | . Load Libraries and Data . %reload_ext autoreload %autoreload 2 . import joblib import numpy as np import os import pandas as pd from pathlib import Path import random from sklearn.model_selection import KFold from sklearn.metrics import mean_squared_error from tqdm import tqdm from warnings import simplefilter simplefilter(&#39;ignore&#39;) . from pytorch_lightning import Trainer, seed_everything from pytorch_lightning.callbacks.early_stopping import EarlyStopping from pytorch_lightning.core.lightning import LightningModule import torch from torch import nn from torch.utils.data import DataLoader, Dataset from transformers import (PreTrainedModel, RobertaModel, RobertaTokenizerFast, RobertaConfig, get_constant_schedule_with_warmup, AdamW) . model_name = &#39;roberta_v1&#39; data_dir = Path(&#39;../input/commonlitreadabilityprize&#39;) train_file = data_dir / &#39;train.csv&#39; test_file = data_dir / &#39;test.csv&#39; sample_file = data_dir / &#39;sample_submission.csv&#39; pretrained_path = &#39;../input/roberta-base/&#39; build_dir = Path(&#39;../build&#39;) output_dir = build_dir / &#39;model&#39; / model_name trn_encoded_file = output_dir / &#39;trn.enc.joblib&#39; tokenizer_file = output_dir / &#39;tokenizer.joblib&#39; val_predict_file = output_dir / f&#39;{model_name}.val.txt&#39; submission_file = output_dir / &#39;submission.csv&#39; id_col = &#39;id&#39; target_col = &#39;target&#39; text_col = &#39;excerpt&#39; max_len = 200 n_fold = 5 n_est = 20 n_stop = 2 batch_size = 8 seed = 42 . output_dir.mkdir(parents=True, exist_ok=True) . seed_everything(seed) . Global seed set to 42 . 42 . if torch.cuda.is_available(): device = torch.device(&quot;cuda&quot;) print(&quot;GPU is available&quot;) else: device = torch.device(&quot;cpu&quot;) print(&quot;GPU not available, CPU used&quot;) . GPU is available . trn = pd.read_csv(train_file, index_col=id_col) tst = pd.read_csv(test_file, index_col=id_col) y = trn[target_col].values print(trn.shape, y.shape) trn.head() . (2834, 5) (2834,) . url_legal license excerpt target standard_error . id . c12129c31 NaN | NaN | When the young people returned to the ballroom... | -0.340259 | 0.464009 | . 85aa80a4c NaN | NaN | All through dinner time, Mrs. Fayre was somewh... | -0.315372 | 0.480805 | . b69ac6792 NaN | NaN | As Roger had predicted, the snow departed as q... | -0.580118 | 0.476676 | . dd1000b26 NaN | NaN | And outside before the palace a great garden w... | -1.054013 | 0.450007 | . 37c1b32fb NaN | NaN | Once upon a time there were Three Bears who li... | 0.247197 | 0.510845 | . Tokenization Using RoBERTa . tokenizer = RobertaTokenizerFast.from_pretrained(pretrained_path, do_lower_case=True) model_config = RobertaConfig.from_pretrained(pretrained_path) model_config.output_hidden_states = True . class Data(Dataset): def __init__(self, df): super().__init__() self.df = df self.labeled = target_col in df def __len__(self): return len(self.df) def __getitem__(self, idx): texts = self.df[text_col][idx] token = tokenizer(texts, max_length=max_len, truncation=True, padding=&#39;max_length&#39;, return_tensors=&#39;pt&#39;, add_special_tokens=True) ids = torch.tensor(token[&#39;input_ids&#39;], dtype=torch.long).squeeze() mask = torch.tensor(token[&#39;attention_mask&#39;], dtype=torch.long).squeeze() if self.labeled: target = torch.tensor(self.df[target_col][idx], dtype=torch.float) return (ids, mask, target) if self.labeled else (ids, mask) . Model Training with Cross-Validation . Simple model with only an output dense layer added to the pre-trained RoBERTa model. . class ReadabilityModel(LightningModule): def __init__(self, conf): super().__init__() self.config = conf self.model = RobertaModel.from_pretrained(pretrained_path, config=self.config) self.dropout = nn.Dropout(0.1) self.num_targets = 1 self.clf = nn.Linear(768, self.num_targets) torch.nn.init.normal_(self.clf.weight, std=0.02) def forward(self, inputs): ids, mask = inputs out = self.model(ids, attention_mask=mask) out = out[&#39;hidden_states&#39;] x = out[-1] x = self.dropout(x) x = torch.mean(x, 1, True) preds = self.clf(x) preds = preds.squeeze(-1).squeeze(-1) return preds def training_step(self, batch, batch_idx): ids, mask, y = batch p = self([ids, mask]) loss = self.loss_fn(p, y) self.log(&#39;train_loss&#39;, loss) return loss def validation_step(self, batch, batch_idx): ids, mask, y = batch p = self([ids, mask]) loss = self.loss_fn(p, y) self.log(&#39;val_loss&#39;, loss) def configure_optimizers(self): optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01) lr_scheduler = get_constant_schedule_with_warmup(optimizer, 100) return [optimizer], [lr_scheduler] def loss_fn(self, p, y): return torch.sqrt(nn.MSELoss()(p, y)) . Training the model with early stopping and a learning-rate schedulerTraining the model . cv = KFold(n_splits=n_fold, shuffle=True, random_state=seed) p = np.zeros_like(y, dtype=float) p_tst = np.zeros((tst.shape[0],), dtype=float) for i_cv, (i_trn, i_val) in enumerate(cv.split(trn), 1): model = ReadabilityModel(model_config) trn_loader = DataLoader(Data(trn.iloc[i_trn]), shuffle=True, batch_size=batch_size) val_loader = DataLoader(Data(trn.iloc[i_val]), shuffle=False, batch_size=batch_size * 8) trainer = Trainer(gpus=[0], max_epochs=n_est, callbacks=[EarlyStopping(monitor=&#39;val_loss&#39;, mode=&#39;min&#39;, patience=n_stop)], checkpoint_callback=False) trainer.fit(model, trn_loader, val_loader) val_loader = DataLoader(Data(trn.iloc[i_val].drop(target_col, axis=1)), shuffle=False, batch_size=batch_size * 8) tst_loader = DataLoader(Data(tst), shuffle=False, batch_size=batch_size * 8) p[i_val] = np.concatenate(trainer.predict(model, val_loader)) p_tst += np.concatenate(trainer.predict(model, tst_loader)) / n_fold trainer.save_checkpoint(f&#39;{model_name}_cv{i_cv}.ckpt&#39;) del trainer, model . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params -- 0 | model | RobertaModel | 124 M 1 | dropout | Dropout | 0 2 | clf | Linear | 769 -- 124 M Trainable params 0 Non-trainable params 124 M Total params 498.586 Total estimated model params size (MB) LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params -- 0 | model | RobertaModel | 124 M 1 | dropout | Dropout | 0 2 | clf | Linear | 769 -- 124 M Trainable params 0 Non-trainable params 124 M Total params 498.586 Total estimated model params size (MB) LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params -- 0 | model | RobertaModel | 124 M 1 | dropout | Dropout | 0 2 | clf | Linear | 769 -- 124 M Trainable params 0 Non-trainable params 124 M Total params 498.586 Total estimated model params size (MB) LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params -- 0 | model | RobertaModel | 124 M 1 | dropout | Dropout | 0 2 | clf | Linear | 769 -- 124 M Trainable params 0 Non-trainable params 124 M Total params 498.586 Total estimated model params size (MB) LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params -- 0 | model | RobertaModel | 124 M 1 | dropout | Dropout | 0 2 | clf | Linear | 769 -- 124 M Trainable params 0 Non-trainable params 124 M Total params 498.586 Total estimated model params size (MB) LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . Print CV RMSE and Save CV Predictions . print(f&#39;CV RMSE: {mean_squared_error(y, p, squared=False):.6f}&#39;) np.savetxt(val_predict_file, p, fmt=&#39;%.6f&#39;) . CV RMSE: 0.678173 . Submission . sub = pd.read_csv(sample_file, index_col=id_col) sub[target_col] = p_tst sub.to_csv(submission_file) sub.head() . target . id . c0f722661 -0.087452 | . f0953f0a5 -0.122406 | . 0df072751 -0.165737 | . 04caf4e0c -2.293868 | . 0e63f8bea -1.454202 | . If you find it helpful, please upvote the notebook. Also check out my other notebooks below: . TF/Keras BERT Baseline (Training/Inference): shares the TF/Keras BERT baseline with 5-fold CV | All Zero Submission: shows the public LB score for all zero submission | DAE with 2 Lines of Code with Kaggler: shows how to generate Denoising AutoEncoder features using Kaggler | . Happy Kagglging~! .",
            "url": "kaggler.com/notebook/kaggle/nlp/2021/05/07/pytorch-lightning-roberta-baseline.html",
            "relUrl": "/notebook/kaggle/nlp/2021/05/07/pytorch-lightning-roberta-baseline.html",
            "date": " • May 7, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Kaggler v0.9.4 Release with Stacked DAE",
            "content": "Today, Kaggler v0.9.4 is released with additional features for DAE as follows: . In addition to the swap noise (swap_prob), the Gaussian noise (noise_std) and zero masking (mask_prob) have been added to DAE to overcome overfitting. | Stacked DAE is available through the n_layer input argument (see Figure 3. in Vincent et al. (2010), “Stacked Denoising Autoencoders” for reference). | . For example, to build a stacking DAE with 3 pairs of encoder/decoder and all three types of noises, you can do: . from kaggler.preprocessing import DAE dae = DAE(cat_cols=cat_cols, num_cols=num_cols, n_layer=3, noise_std=.05, swap_prob=.2, masking_prob=.1) X = dae.fit_transform(pd.concat([trn, tst], axis=0)) . If you’re using previous versions, please upgrade Kaggler using . pip install -U kaggler. . You can find Kaggle notebooks featured with Kaggler’s DAE as follows: . Kaggler DAE + AutoLGB Baseline: shows how to train a LightGBM model using Kaggler’s DAE features and AutoLGB model at the current TPS May competition | DAE with 2 Lines of Code with Kaggler: shows how to use Kaggler’s DAE with the previous TPS April competition. | . Any feedbacks, suggestions, questions for the package are welcome. . Hope it helps! :) .",
            "url": "kaggler.com/kaggler/dae/2021/05/01/kaggler-new-release.html",
            "relUrl": "/kaggler/dae/2021/05/01/kaggler-new-release.html",
            "date": " • May 1, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "DAE with 2 Lines of Code with Kaggler",
            "content": "UPDATE on 5/1/2021 . Today, Kaggler v0.9.4 is released with additional features for DAE as follows: . In addition to the swap noise (swap_prob), the Gaussian noise (noise_std) and zero masking (mask_prob) have been added to DAE to overcome overfitting. | Stacked DAE is available through the n_layer input argument (see Figure 3. in Vincent et al. (2010), &quot;Stacked Denoising Autoencoders&quot; for reference). | . For example, to build a stacked DAE with 3 pairs of encoder/decoder and all three types of noises, you can do: . from kaggler.preprocessing import DAE dae = DAE(cat_cols=cat_cols, num_cols=num_cols, n_layer=3, noise_std=.05, swap_prob=.2, masking_prob=.1) X = dae.fit_transform(pd.concat([trn, tst], axis=0)) . If you&#39;re using previous versions, please upgrade Kaggler using pip install -U kaggler. . . Today I released a new version (v0.9.0) of the Kaggler package with Denoising AutoEncoder (DAE) with the swap noise. . Now you can train a DAE with only 2 lines of code as follows: . dae = DAE(cat_cols=cat_cols, num_cols=num_cols, encoding_dim=encoding_dim) X = dae.fit_transform(df[feature_cols]) . In addition to the new DAE feature encoder, Kaggler supports many of feature transformations used in Kaggle including: . TargetEncoder: with smoothing and cross-validation to avoid overfitting | FrequencyEncoder | LabelEncoder: that imputes missing values and groups rare categories | OneHotEncoder: that imputes missing values and groups rare categories | EmbeddingEncoder: that transforms categorical features into embeddings | QuantileEncoder: that transforms numerical features into quantiles | . In the notebook below, I will show how to use Kaggler&#39;s LabelEncoder, TargetEncoder, and DAE for feature engineering, then use Kaggler&#39;s AutoLGB to do feature selection and hyperparameter optimization. . This notebook was originally published here at Kaggle. . . Today I released a new version (v0.9.0) of the Kaggler package with Denoising AutoEncoder (DAE) with the swap noise. . Now you can train a DAE with only 2 lines of code as follows: . dae = DAE(cat_cols=cat_cols, num_cols=num_cols, encoding_dim=encoding_dim) X = dae.fit_transform(df[feature_cols]) . In addition to the new DAE feature encoder, Kaggler supports many of feature transformations used in Kaggle including: . TargetEncoder: with smoothing and cross-validation to avoid overfitting | FrequencyEncoder | LabelEncoder: that imputes missing values and groups rare categories | OneHotEncoder: that imputes missing values and groups rare categories | EmbeddingEncoder: that transforms categorical features into embeddings | QuantileEncoder: that transforms numerical features into quantiles | . In the notebook below, I will show how to use Kaggler&#39;s LabelEncoder, TargetEncoder, and DAE for feature engineering, then use Kaggler&#39;s AutoLGB to do feature selection and hyperparameter optimization. . Part 1: Data Loading &amp; Feature Engineering . import lightgbm as lgb import numpy as np import pandas as pd from pathlib import Path import tensorflow as tf from tensorflow import keras from sklearn.model_selection import StratifiedKFold from sklearn.preprocessing import StandardScaler from sklearn.metrics import roc_auc_score, confusion_matrix import warnings . !pip install kaggler . import kaggler from kaggler.model import AutoLGB from kaggler.preprocessing import DAE, TargetEncoder, LabelEncoder print(f&#39;Kaggler: {kaggler.__version__}&#39;) . warnings.simplefilter(&#39;ignore&#39;) pd.set_option(&#39;max_columns&#39;, 100) . feature_name = &#39;dae&#39; algo_name = &#39;lgb&#39; model_name = f&#39;{algo_name}_{feature_name}&#39; data_dir = Path(&#39;/kaggle/input/tabular-playground-series-apr-2021/&#39;) trn_file = data_dir / &#39;train.csv&#39; tst_file = data_dir / &#39;test.csv&#39; sample_file = data_dir / &#39;sample_submission.csv&#39; pseudo_label_file = &#39;../input/tps-apr-2021-pseudo-label-dae/tps04-sub-006.csv&#39; feature_file = f&#39;{feature_name}.csv&#39; predict_val_file = f&#39;{model_name}.val.txt&#39; predict_tst_file = f&#39;{model_name}.tst.txt&#39; submission_file = f&#39;{model_name}.sub.csv&#39; target_col = &#39;Survived&#39; id_col = &#39;PassengerId&#39; . n_fold = 5 seed = 42 encoding_dim = 64 . trn = pd.read_csv(trn_file, index_col=id_col) tst = pd.read_csv(tst_file, index_col=id_col) sub = pd.read_csv(sample_file, index_col=id_col) pseudo_label = pd.read_csv(pseudo_label_file, index_col=id_col) print(trn.shape, tst.shape, sub.shape, pseudo_label.shape) . tst[target_col] = pseudo_label[target_col] n_trn = trn.shape[0] df = pd.concat([trn, tst], axis=0) df.head() . df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;No&#39;) df[&#39;Cabin&#39;] = df[&#39;Cabin&#39;].fillna(&#39;_&#39;) df[&#39;CabinType&#39;] = df[&#39;Cabin&#39;].apply(lambda x:x[0]) df.Ticket = df.Ticket.map(lambda x:str(x).split()[0] if len(str(x).split()) &gt; 1 else &#39;X&#39;) df[&#39;Age&#39;].fillna(round(df[&#39;Age&#39;].median()), inplace=True,) df[&#39;Age&#39;] = df[&#39;Age&#39;].apply(round).astype(int) # Fare, fillna with mean value fare_map = df[[&#39;Fare&#39;, &#39;Pclass&#39;]].dropna().groupby(&#39;Pclass&#39;).median().to_dict() df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Pclass&#39;].map(fare_map[&#39;Fare&#39;])) df[&#39;FirstName&#39;] = df[&#39;Name&#39;].str.split(&#39;, &#39;).str[0] df[&#39;SecondName&#39;] = df[&#39;Name&#39;].str.split(&#39;, &#39;).str[1] df[&#39;n&#39;] = 1 gb = df.groupby(&#39;FirstName&#39;) df_names = gb[&#39;n&#39;].sum() df[&#39;SameFirstName&#39;] = df[&#39;FirstName&#39;].apply(lambda x:df_names[x]).fillna(1) gb = df.groupby(&#39;SecondName&#39;) df_names = gb[&#39;n&#39;].sum() df[&#39;SameSecondName&#39;] = df[&#39;SecondName&#39;].apply(lambda x:df_names[x]).fillna(1) df[&#39;Sex&#39;] = (df[&#39;Sex&#39;] == &#39;male&#39;).astype(int) df[&#39;FamilySize&#39;] = df.SibSp + df.Parch + 1 feature_cols = [&#39;Pclass&#39;, &#39;Age&#39;,&#39;Embarked&#39;,&#39;Parch&#39;,&#39;SibSp&#39;,&#39;Fare&#39;,&#39;CabinType&#39;,&#39;Ticket&#39;,&#39;SameFirstName&#39;, &#39;SameSecondName&#39;, &#39;Sex&#39;, &#39;FamilySize&#39;, &#39;FirstName&#39;, &#39;SecondName&#39;] cat_cols = [&#39;Pclass&#39;,&#39;Embarked&#39;,&#39;CabinType&#39;,&#39;Ticket&#39;, &#39;FirstName&#39;, &#39;SecondName&#39;] num_cols = [x for x in feature_cols if x not in cat_cols] print(len(feature_cols), len(cat_cols), len(num_cols)) . for col in [&#39;SameFirstName&#39;, &#39;SameSecondName&#39;, &#39;Fare&#39;, &#39;FamilySize&#39;, &#39;Parch&#39;, &#39;SibSp&#39;]: df[col] = np.log2(1 + df[col]) scaler = StandardScaler() df[num_cols] = scaler.fit_transform(df[num_cols]) . Label encoding with rare category grouping and missing value imputation . lbe = LabelEncoder(min_obs=50) df[cat_cols] = lbe.fit_transform(df[cat_cols]).astype(int) . Target encoding with smoothing and 5-fold cross-validation . cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed) te = TargetEncoder(cv=cv) df_te = te.fit_transform(df[cat_cols], df[target_col]) df_te.columns = [f&#39;te_{col}&#39; for col in cat_cols] df_te.head() . DAE . dae = DAE(cat_cols=cat_cols, num_cols=num_cols, encoding_dim=encoding_dim) X = dae.fit_transform(df[feature_cols]) . df_dae = pd.DataFrame(X, columns=[f&#39;dae_{i}&#39; for i in range(encoding_dim)]) print(df_dae.shape) . Part 2: Model Training . AutoLGB for Feature Selection and Hyperparameter Optimization . X = pd.concat([df[feature_cols], df_te, df_dae], axis=1) y = df[target_col] X_tst = X.iloc[n_trn:] p = np.zeros_like(y, dtype=float) p_tst = np.zeros((tst.shape[0],)) print(f&#39;Training a stacking ensemble LightGBM model:&#39;) for i, (i_trn, i_val) in enumerate(cv.split(X, y)): if i == 0: clf = AutoLGB(objective=&#39;binary&#39;, metric=&#39;auc&#39;, random_state=seed) clf.tune(X.iloc[i_trn], y[i_trn]) features = clf.features params = clf.params n_best = clf.n_best print(f&#39;{n_best}&#39;) print(f&#39;{params}&#39;) print(f&#39;{features}&#39;) trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn]) val_data = lgb.Dataset(X.iloc[i_val], y[i_val]) clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100) p[i_val] = clf.predict(X.iloc[i_val]) p_tst += clf.predict(X_tst) / n_fold print(f&#39;CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}&#39;) . print(f&#39; CV AUC: {roc_auc_score(y, p):.6f}&#39;) print(f&#39;Test AUC: {roc_auc_score(pseudo_label[target_col], p_tst)}&#39;) . Submission . n_pos = int(0.34911 * tst.shape[0]) th = sorted(p_tst, reverse=True)[n_pos] print(th) confusion_matrix(pseudo_label[target_col], (p_tst &gt; th).astype(int)) . sub[target_col] = (p_tst &gt; th).astype(int) sub.to_csv(submission_file) . If you find it useful, please upvote the notebook and leave your feedback. It will be greatly appreciated! . Also please check my previous notebooks as well: . AutoEncoder + Pseudo Label + AutoLGB: shows how to build a basic AutoEncoder using Keras, and perform automated feature selection and hyperparameter optimization using Kaggler&#39;s AutoLGB. | Supervised Emphasized Denoising AutoEncoder: shows how to build a more sophiscated version of AutoEncoder, called supervised emphasized Denoising AutoEncoder (DAE), which trains DAE and a classifier simultaneously. | Stacking Ensemble: shows how to perform stacking ensemble. | .",
            "url": "kaggler.com/notebook/kaggle/2021/04/29/dae-with-2-lines-of-code-with-kaggler.html",
            "relUrl": "/notebook/kaggle/2021/04/29/dae-with-2-lines-of-code-with-kaggler.html",
            "date": " • Apr 29, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Stacking Ensemble",
            "content": "This notebook was originally published here at Kaggle. . . This notebook shows how to perform stacking ensemble (a.k.a. stacked generalization). . In Ensemble-learning meta-classifier for stacking, @remekkinas shares how to do stacking ensemble using MLExtend&#39;s StackingCVClassifier. . To demonstrate how stacking works, this notebook shows how to prepare the baseline model predictions using cross-validation (CV), then use them for level-2 stacking. It trains four classifiers, Random Forests, Extremely Randomized Trees, LightGBM, and CatBoost as level-1 base models. It also uses CV predictions of two models, LightGBM with DAE features and supervised DAE trained from my previous notebook, Supervised Emphasized Denoising AutoEncoder to show why keeping CV predictions for every model is important. :) . The contents of this notebook are as follows: . Feature Engineering: Same as in the Supervised Emphasized Denoising AutoEncoder and AutoEncoder + Pseudo Label + AutoLGB. | Level-1 Base Model Training: Training four base models, Random Forests, Extremely Randomized Trees, LightGBM, and CatBoost using the same 5-fold CV. | Level-2 Stacking: Training the LightGBM model with CV predictions of base models, original features, and DAE features. Performing feature selection and hyperparameter optimization using Kaggler&#39;s AutoLGB. | This notebook is inspired and/or based on other Kagglers&#39; notebooks as follows: . TPS-APR21-EDA+MODEL by @udbhavpangotra | Ensemble-learning meta-classifier for stacking by @remekkinas | TPS Apr 2021 pseudo labeling/voting ensemble by @hiro5299834 | . Thanks! . Part 1: Data Loading &amp; Feature Engineering . from catboost import CatBoostClassifier from joblib import dump import lightgbm as lgb from lightgbm import LGBMClassifier from matplotlib import pyplot as plt import numpy as np import pandas as pd from pathlib import Path from sklearn.ensemble import RandomForestClassifier from sklearn.ensemble import ExtraTreesClassifier from sklearn.metrics import roc_auc_score, confusion_matrix from sklearn.model_selection import StratifiedKFold from sklearn.preprocessing import StandardScaler import warnings . !pip install kaggler . import kaggler from kaggler.model import AutoLGB from kaggler.preprocessing import LabelEncoder print(f&#39;Kaggler: {kaggler.__version__}&#39;) . warnings.simplefilter(&#39;ignore&#39;) pd.set_option(&#39;max_columns&#39;, 100) . data_dir = Path(&#39;/kaggle/input/tabular-playground-series-apr-2021/&#39;) trn_file = data_dir / &#39;train.csv&#39; tst_file = data_dir / &#39;test.csv&#39; sample_file = data_dir / &#39;sample_submission.csv&#39; pseudo_label_file = &#39;/kaggle/input/tps-apr-2021-pseudo-label-dae/tps04-sub-006.csv&#39; dae_feature_file = &#39;/kaggle/input/tps-apr-2021-pseudo-label-dae/dae.csv&#39; lgb_dae_predict_val_file = &#39;/kaggle/input/tps-apr-2021-pseudo-label-dae/lgb_dae.val.txt&#39; lgb_dae_predict_tst_file = &#39;/kaggle/input/tps-apr-2021-pseudo-label-dae/lgb_dae.tst.txt&#39; sdae_dae_predict_val_file = &#39;/kaggle/input/tps-apr-2021-pseudo-label-dae/sdae_dae.val.txt&#39; sdae_dae_predict_tst_file = &#39;/kaggle/input/tps-apr-2021-pseudo-label-dae/sdae_dae.tst.txt&#39; target_col = &#39;Survived&#39; id_col = &#39;PassengerId&#39; feature_name = &#39;dae&#39; algo_name = &#39;esb&#39; model_name = f&#39;{algo_name}_{feature_name}&#39; feature_file = f&#39;{feature_name}.csv&#39; predict_val_file = f&#39;{model_name}.val.txt&#39; predict_tst_file = f&#39;{model_name}.tst.txt&#39; submission_file = f&#39;{model_name}.sub.csv&#39; . n_fold = 5 seed = 42 n_est = 1000 encoding_dim = 128 . trn = pd.read_csv(trn_file, index_col=id_col) tst = pd.read_csv(tst_file, index_col=id_col) sub = pd.read_csv(sample_file, index_col=id_col) pseudo_label = pd.read_csv(pseudo_label_file, index_col=id_col) dae_features = np.loadtxt(dae_feature_file, delimiter=&#39;,&#39;) lgb_dae_predict_val = np.loadtxt(lgb_dae_predict_val_file) lgb_dae_predict_tst = np.loadtxt(lgb_dae_predict_tst_file) sdae_dae_predict_val = np.loadtxt(sdae_dae_predict_val_file) sdae_dae_predict_tst = np.loadtxt(sdae_dae_predict_tst_file) print(trn.shape, tst.shape, sub.shape, pseudo_label.shape, dae_features.shape) print(lgb_dae_predict_val.shape, lgb_dae_predict_tst.shape) print(sdae_dae_predict_val.shape, sdae_dae_predict_tst.shape) . tst[target_col] = pseudo_label[target_col] n_trn = trn.shape[0] df = pd.concat([trn, tst], axis=0) df.head() . Loading 128 DAE features generated from Supervised Emphasized Denoising AutoEncoder. . df_dae = pd.DataFrame(dae_features, columns=[f&#39;enc_{x}&#39; for x in range(encoding_dim)]) print(df_dae.shape) df_dae.head() . Feature engineering using @udbhavpangotra&#39;s code. . df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;No&#39;) df[&#39;Cabin&#39;] = df[&#39;Cabin&#39;].fillna(&#39;_&#39;) df[&#39;CabinType&#39;] = df[&#39;Cabin&#39;].apply(lambda x:x[0]) df.Ticket = df.Ticket.map(lambda x:str(x).split()[0] if len(str(x).split()) &gt; 1 else &#39;X&#39;) df[&#39;Age&#39;].fillna(round(df[&#39;Age&#39;].median()), inplace=True,) df[&#39;Age&#39;] = df[&#39;Age&#39;].apply(round).astype(int) # Fare, fillna with mean value fare_map = df[[&#39;Fare&#39;, &#39;Pclass&#39;]].dropna().groupby(&#39;Pclass&#39;).median().to_dict() df[&#39;Fare&#39;] = df[&#39;Fare&#39;].fillna(df[&#39;Pclass&#39;].map(fare_map[&#39;Fare&#39;])) df[&#39;FirstName&#39;] = df[&#39;Name&#39;].str.split(&#39;, &#39;).str[0] df[&#39;SecondName&#39;] = df[&#39;Name&#39;].str.split(&#39;, &#39;).str[1] df[&#39;n&#39;] = 1 gb = df.groupby(&#39;FirstName&#39;) df_names = gb[&#39;n&#39;].sum() df[&#39;SameFirstName&#39;] = df[&#39;FirstName&#39;].apply(lambda x:df_names[x]).fillna(1) gb = df.groupby(&#39;SecondName&#39;) df_names = gb[&#39;n&#39;].sum() df[&#39;SameSecondName&#39;] = df[&#39;SecondName&#39;].apply(lambda x:df_names[x]).fillna(1) df[&#39;Sex&#39;] = (df[&#39;Sex&#39;] == &#39;male&#39;).astype(int) df[&#39;FamilySize&#39;] = df.SibSp + df.Parch + 1 feature_cols = [&#39;Pclass&#39;, &#39;Age&#39;,&#39;Embarked&#39;,&#39;Parch&#39;,&#39;SibSp&#39;,&#39;Fare&#39;,&#39;CabinType&#39;,&#39;Ticket&#39;,&#39;SameFirstName&#39;, &#39;SameSecondName&#39;, &#39;Sex&#39;, &#39;FamilySize&#39;, &#39;FirstName&#39;, &#39;SecondName&#39;] cat_cols = [&#39;Pclass&#39;,&#39;Embarked&#39;,&#39;CabinType&#39;,&#39;Ticket&#39;, &#39;FirstName&#39;, &#39;SecondName&#39;] num_cols = [x for x in feature_cols if x not in cat_cols] print(len(feature_cols), len(cat_cols), len(num_cols)) . Applying log2(1 + x) for numerical features and label-encoding categorical features using kaggler.preprocessing.LabelEncoder, which handles NaNs and groups rare categories together. . for col in [&#39;SameFirstName&#39;, &#39;SameSecondName&#39;, &#39;Fare&#39;, &#39;FamilySize&#39;, &#39;Parch&#39;, &#39;SibSp&#39;]: df[col] = np.log2(1 + df[col]) scaler = StandardScaler() df[num_cols] = scaler.fit_transform(df[num_cols]) lbe = LabelEncoder(min_obs=50) df[cat_cols] = lbe.fit_transform(df[cat_cols]).astype(int) . Part 2: Level-1 Base Model Training . lgb_params = { &#39;metric&#39;: &#39;binary_logloss&#39;, &#39;n_estimators&#39;: n_est, &#39;objective&#39;: &#39;binary&#39;, &#39;random_state&#39;: seed, &#39;learning_rate&#39;: 0.01, &#39;min_child_samples&#39;: 20, &#39;reg_alpha&#39;: 3e-5, &#39;reg_lambda&#39;: 9e-2, &#39;num_leaves&#39;: 63, &#39;colsample_bytree&#39;: 0.8, &#39;subsample&#39;: 0.8, } ctb_params = { &#39;bootstrap_type&#39;: &#39;Poisson&#39;, &#39;loss_function&#39;: &#39;Logloss&#39;, &#39;eval_metric&#39;: &#39;Logloss&#39;, &#39;random_seed&#39;: seed, &#39;task_type&#39;: &#39;GPU&#39;, &#39;max_depth&#39;: 8, &#39;learning_rate&#39;: 0.01, &#39;n_estimators&#39;: n_est, &#39;max_bin&#39;: 280, &#39;min_data_in_leaf&#39;: 64, &#39;l2_leaf_reg&#39;: 0.01, &#39;subsample&#39;: 0.8 } rf_params = { &#39;max_depth&#39;: 15, &#39;min_samples_leaf&#39;: 8, &#39;random_state&#39;: seed } . base_models = {&#39;rf&#39;: RandomForestClassifier(**rf_params), &#39;cbt&#39;: CatBoostClassifier(**ctb_params, verbose=None, logging_level=&#39;Silent&#39;), &#39;lgb&#39;: LGBMClassifier(**lgb_params), &#39;et&#39;: ExtraTreesClassifier(bootstrap=True, criterion=&#39;entropy&#39;, max_features=0.55, min_samples_leaf=8, min_samples_split=4, n_estimators=100)} . Make sure that you use the same CV folds across all level-1 models. . from copy import copy X = pd.concat((df[feature_cols], df_dae), axis=1) y = df[target_col] X_tst = X.iloc[n_trn:] cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed) p_dict = {} for name in base_models: print(f&#39;Training {name}:&#39;) p = np.zeros_like(y, dtype=float) p_tst = np.zeros((tst.shape[0],)) for i, (i_trn, i_val) in enumerate(cv.split(X, y)): clf = copy(base_models[name]) clf.fit(X.iloc[i_trn], y[i_trn]) p[i_val] = clf.predict_proba(X.iloc[i_val])[:, 1] print(f&#39; tCV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}&#39;) p_dict[name] = p print(f&#39; tCV AUC: {roc_auc_score(y, p):.6f}&#39;) . Adding CV predictions of two additional models trained separately. You can use all models trained throughout the competition as long as those are traine d with the same CV folds. . ALWAYS SAVE CV PREDICTIONS!!! . p_dict.update({ &#39;lgb_dae&#39;: lgb_dae_predict_val, &#39;sdae_dae&#39;: sdae_dae_predict_val }) dump(p_dict, &#39;predict_val_dict.joblib&#39;) . Part 3: Level-2 Stacking . Training a level-2 LightGBM model with the level-1 model CV predictions, original features, and DAE features as inputs. If you have enough level-1 model predictions, you can train level-2 models only with level-1 model predictions. Here, since we only have six level-1 models, we use additional features and perform feature selection. . X = pd.concat([pd.DataFrame(p_dict), df[feature_cols], df_dae], axis=1) X_tst = X.iloc[n_trn:] p = np.zeros_like(y, dtype=float) p_tst = np.zeros((tst.shape[0],)) print(f&#39;Training a stacking ensemble LightGBM model:&#39;) for i, (i_trn, i_val) in enumerate(cv.split(X, y)): if i == 0: clf = AutoLGB(objective=&#39;binary&#39;, metric=&#39;auc&#39;, random_state=seed) clf.tune(X.iloc[i_trn], y[i_trn]) features = clf.features params = clf.params n_best = clf.n_best print(f&#39;{n_best}&#39;) print(f&#39;{params}&#39;) print(f&#39;{features}&#39;) trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn]) val_data = lgb.Dataset(X.iloc[i_val], y[i_val]) clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100) p[i_val] = clf.predict(X.iloc[i_val]) p_tst += clf.predict(X_tst) / n_fold print(f&#39;CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}&#39;) . print(f&#39; CV AUC: {roc_auc_score(y, p):.6f}&#39;) print(f&#39;Test AUC: {roc_auc_score(pseudo_label[target_col], p_tst)}&#39;) . n_pos = int(0.34911 * tst.shape[0]) th = sorted(p_tst, reverse=True)[n_pos] print(th) confusion_matrix(pseudo_label[target_col], (p_tst &gt; th).astype(int)) . sub[target_col] = (p_tst &gt; th).astype(int) sub.to_csv(submission_file) . If you find it useful, please upvote the notebook and leave your feedback. It will be greatly appreciated! . Also please check out my previous notebooks as follows: . AutoEncoder + Pseudo Label + AutoLGB: shows how to build a basic AutoEncoder using Keras, and perform automated feature selection and hyperparameter optimization using Kaggler&#39;s AutoLGB. | Supervised Emphasized Denoising AutoEncoder: shows how to build a more sophiscated version of AutoEncoder, called supervised emphasized Denoising AutoEncoder (DAE), which trains DAE and a classifier simultaneously. | . Happy Kaggling! ;) .",
            "url": "kaggler.com/notebook/kaggle/2021/04/26/stacking-ensemble.html",
            "relUrl": "/notebook/kaggle/2021/04/26/stacking-ensemble.html",
            "date": " • Apr 26, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Supervised Emphasized Denoising AutoEncoder",
            "content": "This notebook was originally published here at Kaggle. . . In this notebook, I will show how to build supervised emphasized Denoising AutoEncoder (DAE) with Keras. With pseudo label, we can train a classifier and the DAE together instead of training them separately as done in previous TPS competitions. . If you&#39;re interested in how different components of DAE (denoising, stacked layers, emphasis, etc.) contribute to its performance, please check out Vincent et al. (2010) &quot;Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion&quot;, JMLR. . This notebook is built on top of my previous notebook, AutoEncoder + Pseudo Label + AutoLGB. The first part (section 1, 2, 3 and 5) of the notebook is the same as the previous one. . The contents of the notebook are as follows: . Package Installation: Installing latest version of Kaggler using Pip. | Feature Engineering: code by @udbhavpangotra | Feature Transformation: Using kaggler.preprocessing.LabelEncoder to impute missing values and group rare categories automatically. | Stacked Emphasized Denoising AutoEncoder (DAE): Adding random noise mask and emphasized version of AutoEncoder, called &quot;Embphasized Denoising AutoEncoder&quot;. | LightGBM Model Training: 5-fold CV + Pseudo label from @hiro5299834&#39;s data + kaggler.model.AutoLGB&#39;s feature selection and hyperparameter optimization | Supervised DAE: Training the classifier and DAE simultaneously. | Part 1: DAE + AutoLGB . Load Libraries and Install Kaggler . # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here&#39;s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only &quot;../input/&quot; directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): for filename in filenames: print(os.path.join(dirname, filename)) # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won&#39;t be saved outside of the current session . import lightgbm as lgb from matplotlib import pyplot as plt import numpy as np import pandas as pd from pathlib import Path import tensorflow as tf from tensorflow import keras from tensorflow.keras import backend as K from tensorflow.keras.losses import mean_squared_error from tensorflow.keras.metrics import AUC from tensorflow.python.keras.utils import control_flow_util import seaborn as sns from sklearn.model_selection import StratifiedKFold from sklearn.preprocessing import StandardScaler from sklearn.metrics import roc_auc_score, confusion_matrix import warnings . !pip install kaggler . import kaggler from kaggler.model import AutoLGB from kaggler.preprocessing import LabelEncoder print(f&#39;Kaggler: {kaggler.__version__}&#39;) print(f&#39;TensorFlow: {tf.__version__}&#39;) . warnings.simplefilter(&#39;ignore&#39;) plt.style.use(&#39;fivethirtyeight&#39;) pd.set_option(&#39;max_columns&#39;, 100) . Feature Engineering (ref: code by @udbhavpangotra) . data_dir = Path(&#39;/kaggle/input/tabular-playground-series-apr-2021/&#39;) trn_file = data_dir / &#39;train.csv&#39; tst_file = data_dir / &#39;test.csv&#39; sample_file = data_dir / &#39;sample_submission.csv&#39; pseudo_label_file = &#39;/kaggle/input/tps-apr-2021-label/voting_submission_from_5_best.csv&#39; target_col = &#39;Survived&#39; id_col = &#39;PassengerId&#39; feature_name = &#39;dae&#39; algo_name = &#39;lgb&#39; model_name = f&#39;{algo_name}_{feature_name}&#39; feature_file = f&#39;{feature_name}.csv&#39; predict_val_file = f&#39;{model_name}.val.txt&#39; predict_tst_file = f&#39;{model_name}.tst.txt&#39; submission_file = f&#39;{model_name}.sub.csv&#39; . trn = pd.read_csv(trn_file, index_col=id_col) tst = pd.read_csv(tst_file, index_col=id_col) sub = pd.read_csv(sample_file, index_col=id_col) pseudo_label = pd.read_csv(pseudo_label_file, index_col=id_col) print(trn.shape, tst.shape, sub.shape, pseudo_label.shape) . tst[target_col] = pseudo_label[target_col] n_trn = trn.shape[0] df = pd.concat([trn, tst], axis=0) df.head() . df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;No&#39;) df[&#39;Cabin&#39;] = df[&#39;Cabin&#39;].fillna(&#39;_&#39;) df[&#39;CabinType&#39;] = df[&#39;Cabin&#39;].apply(lambda x:x[0]) df.Ticket = df.Ticket.map(lambda x:str(x).split()[0] if len(str(x).split()) &gt; 1 else &#39;X&#39;) df[&#39;Age&#39;].fillna(round(df[&#39;Age&#39;].median()), inplace=True,) df[&#39;Age&#39;] = df[&#39;Age&#39;].apply(round).astype(int) df[&#39;Fare&#39;].fillna(round(df[&#39;Fare&#39;].median()), inplace=True,) df[&#39;FirstName&#39;] = df[&#39;Name&#39;].str.split(&#39;, &#39;).str[0] df[&#39;SecondName&#39;] = df[&#39;Name&#39;].str.split(&#39;, &#39;).str[1] df[&#39;n&#39;] = 1 gb = df.groupby(&#39;FirstName&#39;) df_names = gb[&#39;n&#39;].sum() df[&#39;SameFirstName&#39;] = df[&#39;FirstName&#39;].apply(lambda x:df_names[x]) gb = df.groupby(&#39;SecondName&#39;) df_names = gb[&#39;n&#39;].sum() df[&#39;SameSecondName&#39;] = df[&#39;SecondName&#39;].apply(lambda x:df_names[x]) df[&#39;Sex&#39;] = (df[&#39;Sex&#39;] == &#39;male&#39;).astype(int) df[&#39;FamilySize&#39;] = df.SibSp + df.Parch + 1 feature_cols = [&#39;Pclass&#39;, &#39;Age&#39;,&#39;Embarked&#39;,&#39;Parch&#39;,&#39;SibSp&#39;,&#39;Fare&#39;,&#39;CabinType&#39;,&#39;Ticket&#39;,&#39;SameFirstName&#39;, &#39;SameSecondName&#39;, &#39;Sex&#39;, &#39;FamilySize&#39;, &#39;FirstName&#39;, &#39;SecondName&#39;] cat_cols = [&#39;Pclass&#39;,&#39;Embarked&#39;,&#39;CabinType&#39;,&#39;Ticket&#39;, &#39;FirstName&#39;, &#39;SecondName&#39;] num_cols = [x for x in feature_cols if x not in cat_cols] print(len(feature_cols), len(cat_cols), len(num_cols)) . Feature Transformation Using Kaggler . for col in [&#39;SameFirstName&#39;, &#39;SameSecondName&#39;, &#39;Fare&#39;, &#39;FamilySize&#39;, &#39;Parch&#39;, &#39;SibSp&#39;]: df[col] = np.log2(1 + df[col]) scaler = StandardScaler() df[num_cols] = scaler.fit_transform(df[num_cols]) lbe = LabelEncoder(min_obs=50) df[cat_cols] = lbe.fit_transform(df[cat_cols]).astype(int) . Emphasized Denoising AutoEncoder (DAE) Using Keras . encoding_dim = 128 masking_prob = .2 emphasis_ratio = 2. seed = 42 def get_dae(encoding_dim, dropout=.2): num_dim = len(num_cols) num_input = keras.layers.Input((num_dim,), name=&#39;num_input&#39;) cat_inputs = [] cat_embs = [] emb_dims = 0 for col in cat_cols: cat_input = keras.layers.Input((1,), name=f&#39;{col}_input&#39;) emb_dim = max(8, int(np.log2(1 + df[col].nunique()) * 4)) cat_emb = keras.layers.Embedding(input_dim=df[col].max() + 1, output_dim=emb_dim)(cat_input) cat_emb = keras.layers.Dropout(dropout)(cat_emb) cat_emb = keras.layers.Reshape((emb_dim,))(cat_emb) cat_inputs.append(cat_input) cat_embs.append(cat_emb) emb_dims += emb_dim merged_inputs = keras.layers.Concatenate()([num_input] + cat_embs) batch_size, merged_inputs_dim = merged_inputs.get_shape() training = K.learning_phase() def mask_inputs(): mask = tf.random.stateless_binomial(shape=(batch_size, merged_inputs_dim), seed=seed, counts=tf.ones((merged_inputs_dim,)), probs=[masking_prob] * merged_inputs_dim) return tf.where(mask == 1, tf.zeros_like(merged_inputs), merged_inputs) masked_inputs = control_flow_util.smart_cond(training, mask_inputs, lambda: merged_inputs) encoded = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(masked_inputs) encoded = keras.layers.Dropout(dropout)(encoded) encoded = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(encoded) encoded = keras.layers.Dropout(dropout)(encoded) encoded = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(encoded) decoded = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(encoded) decoded = keras.layers.Dropout(dropout)(decoded) decoded = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(decoded) decoded = keras.layers.Dropout(dropout)(decoded) decoded = keras.layers.Dense(num_dim + emb_dims, activation=&#39;linear&#39;)(decoded) encoder = keras.Model([num_input] + cat_inputs, encoded) ae = keras.Model([num_input] + cat_inputs, decoded, name=&#39;ae&#39;) reconstruction_loss = K.mean( # masked inputs mean_squared_error(merged_inputs, tf.where(merged_inputs != masked_inputs, decoded, merged_inputs)) / masking_prob * emphasis_ratio # original inputs + mean_squared_error(merged_inputs, tf.where(merged_inputs == masked_inputs, decoded, merged_inputs)) / (1. - masking_prob) ) ae.add_loss(reconstruction_loss) ae.compile(optimizer=&#39;adam&#39;) return ae, encoder . ae, encoder = get_dae(encoding_dim) ae.summary() . inputs = [df[num_cols].values] + [df[x].values for x in cat_cols] ae.fit(inputs, inputs, epochs=30, batch_size=16384, shuffle=True, validation_split=.2) . encoding = encoder.predict(inputs) print(encoding.shape) np.savetxt(feature_file, encoding, fmt=&#39;%.6f&#39;, delimiter=&#39;,&#39;) . Model Training + Feature Selection + HPO Using Kaggler&#39;s AutoLGB . n_fold = 5 X = pd.concat((df[feature_cols], pd.DataFrame(encoding, columns=[f&#39;enc_{x}&#39; for x in range(encoding_dim)])), axis=1) y = df[target_col] X_tst = X.iloc[n_trn:] cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed) p = np.zeros_like(y, dtype=float) p_tst = np.zeros((tst.shape[0],)) for i, (i_trn, i_val) in enumerate(cv.split(X, y)): if i == 0: clf = AutoLGB(objective=&#39;binary&#39;, metric=&#39;auc&#39;, random_state=seed) clf.tune(X.iloc[i_trn], y[i_trn]) features = clf.features params = clf.params n_best = clf.n_best print(f&#39;{n_best}&#39;) print(f&#39;{params}&#39;) print(f&#39;{features}&#39;) trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn]) val_data = lgb.Dataset(X.iloc[i_val], y[i_val]) clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100) p[i_val] = clf.predict(X.iloc[i_val]) p_tst += clf.predict(X_tst) / n_fold print(f&#39;CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}&#39;) np.savetxt(predict_val_file, p, fmt=&#39;%.6f&#39;) np.savetxt(predict_tst_file, p_tst, fmt=&#39;%.6f&#39;) . print(f&#39; CV AUC: {roc_auc_score(y, p):.6f}&#39;) print(f&#39;Test AUC: {roc_auc_score(pseudo_label[target_col], p_tst)}&#39;) . Submission File for DAE + AutoLGB . n_pos = int(0.34911 * tst.shape[0]) th = sorted(p_tst, reverse=True)[n_pos] print(th) confusion_matrix(pseudo_label[target_col], (p_tst &gt; th).astype(int)) . sub[target_col] = (p_tst &gt; th).astype(int) sub.to_csv(submission_file) . Part 2: Supervised DAE . feature_name = &#39;dae&#39; algo_name = &#39;sdae&#39; model_name = f&#39;{algo_name}_{feature_name}&#39; feature_file = f&#39;{feature_name}.csv&#39; predict_val_file = f&#39;{model_name}.val.txt&#39; predict_tst_file = f&#39;{model_name}.tst.txt&#39; submission_file = f&#39;{model_name}.sub.csv&#39; . Supervised DAE with Keras . We are adding a classifier head to the DAE network. It requires the additional loss and metric for the classifier in addition to the reconstruction_loss for DAE. . def get_sdae(encoding_dim, dropout=.2): num_dim = len(num_cols) num_input = keras.layers.Input((num_dim,), name=&#39;num_input&#39;) cat_inputs = [] cat_embs = [] emb_dims = 0 for col in cat_cols: cat_input = keras.layers.Input((1,), name=f&#39;{col}_input&#39;) emb_dim = max(8, int(np.log2(1 + df[col].nunique()) * 4)) cat_emb = keras.layers.Embedding(input_dim=df[col].max() + 1, output_dim=emb_dim)(cat_input) cat_emb = keras.layers.Dropout(dropout)(cat_emb) cat_emb = keras.layers.Reshape((emb_dim,))(cat_emb) cat_inputs.append(cat_input) cat_embs.append(cat_emb) emb_dims += emb_dim inputs = [num_input] + cat_inputs merged_inputs = keras.layers.Concatenate()([num_input] + cat_embs) # masking batch_size, merged_inputs_dim = merged_inputs.get_shape() training = K.learning_phase() def mask_inputs(): mask = tf.random.stateless_binomial(shape=(batch_size, merged_inputs_dim), seed=seed, counts=tf.ones((merged_inputs_dim,)), probs=[masking_prob] * merged_inputs_dim) return tf.where(mask == 1, tf.zeros_like(merged_inputs), merged_inputs) masked_inputs = control_flow_util.smart_cond(training, mask_inputs, lambda: merged_inputs) # encoder encoded_1 = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(masked_inputs) encoded_1 = keras.layers.Dropout(dropout)(encoded_1) encoded_2 = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(encoded_1) encoded_2 = keras.layers.Dropout(dropout)(encoded_2) encoded_3 = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(encoded_2) encoded_concat = keras.layers.Concatenate()([encoded_1, encoded_2, encoded_3]) encoder = keras.Model(inputs, encoded_concat) decoded = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(encoded_3) decoded = keras.layers.Dropout(dropout)(decoded) decoded = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(decoded) decoded = keras.layers.Dropout(dropout)(decoded) decoded = keras.layers.Dense(num_dim + emb_dims, activation=&#39;linear&#39;)(decoded) ae = keras.Model([num_input] + cat_inputs, decoded) # classifier clf_encoded_input = keras.Input((encoding_dim * 3,)) x = keras.layers.Dense(encoding_dim, &#39;relu&#39;)(clf_encoded_input) x = keras.layers.Dropout(dropout)(x) clf_output = keras.layers.Dense(1, activation=&#39;sigmoid&#39;)(x) clf = keras.Model(inputs=clf_encoded_input, outputs=clf_output, name=&#39;clf&#39;) outputs = [ae(inputs), clf(encoder(inputs))] model = keras.Model(inputs, outputs, name=&#39;sdae&#39;) reconstruction_loss = K.mean( # masked inputs mean_squared_error(merged_inputs, tf.where(merged_inputs != masked_inputs, decoded, merged_inputs)) / masking_prob * emphasis_ratio # original inputs + mean_squared_error(merged_inputs, tf.where(merged_inputs == masked_inputs, decoded, merged_inputs)) / (1. - masking_prob) ) model.add_loss(reconstruction_loss) model.compile(optimizer=&#39;adam&#39;, loss={&#39;clf&#39;: &#39;binary_crossentropy&#39;}, metrics={&#39;clf&#39;: [AUC()]}) return model, encoder . sdae, encoder = get_sdae(encoding_dim) sdae.summary() . Model Training: Supervised DAE with 5-CV . n_fold = 5 X = df[feature_cols] y = df[target_col] X_tst = X.iloc[n_trn:] inputs_tst = [X_tst[num_cols].values] + [X_tst[x].values for x in cat_cols] cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed) p = np.zeros_like(y, dtype=float) p_tst = np.zeros((tst.shape[0],)) for i, (i_trn, i_val) in enumerate(cv.split(X, y)): X_trn = X.iloc[i_trn] X_val = X.iloc[i_val] inputs_trn = [X[num_cols].values[i_trn]] + [X[x].values[i_trn] for x in cat_cols] inputs_val = [X[num_cols].values[i_val]] + [X[x].values[i_val] for x in cat_cols] sdae, _ = get_sdae(encoding_dim) sdae.fit(inputs_trn, y[i_trn], epochs=20, batch_size=16384, shuffle=True, validation_data=(inputs_val, y[i_val])) p[i_val] = sdae.predict(inputs_val)[1].flatten() p_tst += sdae.predict(inputs_tst)[1].flatten() / n_fold print(f&#39;CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}&#39;) np.savetxt(predict_val_file, p, fmt=&#39;%.6f&#39;) np.savetxt(predict_tst_file, p_tst, fmt=&#39;%.6f&#39;) . print(f&#39; CV AUC: {roc_auc_score(y, p):.6f}&#39;) print(f&#39;Test AUC: {roc_auc_score(pseudo_label[target_col], p_tst)}&#39;) . n_pos = int(0.34911 * tst.shape[0]) th = sorted(p_tst, reverse=True)[n_pos] print(th) confusion_matrix(pseudo_label[target_col], (p_tst &gt; th).astype(int)) . sub[target_col] = (p_tst &gt; th).astype(int) sub.to_csv(submission_file) . Part 3: Simple Ensemble . submission_file = &#39;simple_ensemble_dae.csv&#39; model_names = [&#39;lgb_dae&#39;, &#39;sdae_dae&#39;] predict_val_files = [f&#39;{x}.val.txt&#39; for x in model_names] predict_tst_files = [f&#39;{x}.tst.txt&#39; for x in model_names] dict_val_predict = {} dict_tst_predict = {} for name, val_file, tst_file in zip(model_name, predict_val_files, predict_tst_files): dict_val_predict[name] = np.loadtxt(val_file) dict_tst_predict[name] = np.loadtxt(tst_file) p = pd.DataFrame(dict_val_predict).mean(axis=1).values p_tst = pd.DataFrame(dict_tst_predict).mean(axis=1).values print(f&#39; CV AUC: {roc_auc_score(y, p):.6f}&#39;) print(f&#39;Test AUC: {roc_auc_score(pseudo_label[target_col], p_tst)}&#39;) . n_pos = int(0.34911 * tst.shape[0]) th = sorted(p_tst, reverse=True)[n_pos] print(th) confusion_matrix(pseudo_label[target_col], (p_tst &gt; th).astype(int)) . sub[target_col] = (p_tst &gt; th).astype(int) sub.to_csv(submission_file) . If you find it helpful, please upvote the notebook and give a star to Kaggler. If you have questions and/or feature requests for Kaggler, please post them as Issue in the Kaggler GitHub repository. . Happy Kaggling! .",
            "url": "kaggler.com/notebook/kaggle/2021/04/21/supervised-emphasized-denoising-autoencoder.html",
            "relUrl": "/notebook/kaggle/2021/04/21/supervised-emphasized-denoising-autoencoder.html",
            "date": " • Apr 21, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "AutoEncoder + Pseudo Label + AutoLGB",
            "content": "This notebook was originally published here at Kaggle. . . In this notebook, I will show how to use autoencoder, feature selection, hyperparameter optimization, and pseudo labeling using the Keras and Kaggler Python packages. . The contents of the notebook are as follows: . Package installation: Installing latest version of Kaggler using Pip | Regular feature engineering: code by @udbhavpangotra | Feature transformation: Using kaggler.preprocessing.LabelEncoder to impute missing values and group rare categories automatically. | Stacked AutoEncoder: Notebooks for DAE will be shared later. | Model training: with 5-fold CV and pseudo label from @hiro5299834&#39;s data. | Feature selection and hyperparameter optimization: Using kaggler.model.AutoLGB | Saving a submission file | Load libraries and install Kaggler . # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here&#39;s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only &quot;../input/&quot; directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname, _, filenames in os.walk(&#39;/kaggle/input&#39;): for filename in filenames: print(os.path.join(dirname, filename)) # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; # You can also write temporary files to /kaggle/temp/, but they won&#39;t be saved outside of the current session . %matplotlib inline import lightgbm as lgb from matplotlib import pyplot as plt import numpy as np import pandas as pd from pathlib import Path import tensorflow as tf from tensorflow import keras import seaborn as sns from sklearn.model_selection import StratifiedKFold from sklearn.preprocessing import StandardScaler from sklearn.metrics import roc_auc_score, confusion_matrix import warnings . !pip install kaggler . import kaggler from kaggler.model import AutoLGB from kaggler.preprocessing import LabelEncoder print(f&#39;Kaggler: {kaggler.__version__}&#39;) print(f&#39;TensorFlow: {tf.__version__}&#39;) . warnings.simplefilter(&#39;ignore&#39;) plt.style.use(&#39;fivethirtyeight&#39;) pd.set_option(&#39;max_columns&#39;, 100) . Feature Engineering (ref: code by @udbhavpangotra) . feature_name = &#39;ae&#39; algo_name = &#39;lgb&#39; model_name = f&#39;{algo_name}_{feature_name}&#39; data_dir = Path(&#39;/kaggle/input/tabular-playground-series-apr-2021/&#39;) trn_file = data_dir / &#39;train.csv&#39; tst_file = data_dir / &#39;test.csv&#39; sample_file = data_dir / &#39;sample_submission.csv&#39; pseudo_label_file = &#39;/kaggle/input/tps-apr-2021-label/voting_submission_from_5_best.csv&#39; feature_file = f&#39;{feature_name}.csv&#39; predict_val_file = f&#39;{model_name}.val.txt&#39; predict_tst_file = f&#39;{model_name}.tst.txt&#39; submission_file = f&#39;{model_name}.sub.csv&#39; target_col = &#39;Survived&#39; id_col = &#39;PassengerId&#39; . trn = pd.read_csv(trn_file, index_col=id_col) tst = pd.read_csv(tst_file, index_col=id_col) sub = pd.read_csv(sample_file, index_col=id_col) pseudo_label = pd.read_csv(pseudo_label_file, index_col=id_col) print(trn.shape, tst.shape, sub.shape, pseudo_label.shape) . tst[target_col] = pseudo_label[target_col] n_trn = trn.shape[0] df = pd.concat([trn, tst], axis=0) df.head() . df.info() . df.describe() . df.nunique() . df[&#39;Embarked&#39;] = df[&#39;Embarked&#39;].fillna(&#39;No&#39;) df[&#39;Cabin&#39;] = df[&#39;Cabin&#39;].fillna(&#39;_&#39;) df[&#39;CabinType&#39;] = df[&#39;Cabin&#39;].apply(lambda x:x[0]) df.Ticket = df.Ticket.map(lambda x:str(x).split()[0] if len(str(x).split()) &gt; 1 else &#39;X&#39;) df[&#39;Age&#39;].fillna(round(df[&#39;Age&#39;].median()), inplace=True,) df[&#39;Age&#39;] = df[&#39;Age&#39;].apply(round).astype(int) df[&#39;Fare&#39;].fillna(round(df[&#39;Fare&#39;].median()), inplace=True,) df[&#39;FirstName&#39;] = df[&#39;Name&#39;].str.split(&#39;, &#39;).str[0] df[&#39;SecondName&#39;] = df[&#39;Name&#39;].str.split(&#39;, &#39;).str[1] df[&#39;n&#39;] = 1 gb = df.groupby(&#39;FirstName&#39;) df_names = gb[&#39;n&#39;].sum() df[&#39;SameFirstName&#39;] = df[&#39;FirstName&#39;].apply(lambda x:df_names[x]) gb = df.groupby(&#39;SecondName&#39;) df_names = gb[&#39;n&#39;].sum() df[&#39;SameSecondName&#39;] = df[&#39;SecondName&#39;].apply(lambda x:df_names[x]) df[&#39;Sex&#39;] = (df[&#39;Sex&#39;] == &#39;male&#39;).astype(int) df[&#39;FamilySize&#39;] = df.SibSp + df.Parch + 1 feature_cols = [&#39;Pclass&#39;, &#39;Age&#39;,&#39;Embarked&#39;,&#39;Parch&#39;,&#39;SibSp&#39;,&#39;Fare&#39;,&#39;CabinType&#39;,&#39;Ticket&#39;,&#39;SameFirstName&#39;, &#39;SameSecondName&#39;, &#39;Sex&#39;, &#39;FamilySize&#39;, &#39;FirstName&#39;, &#39;SecondName&#39;] cat_cols = [&#39;Pclass&#39;,&#39;Embarked&#39;,&#39;CabinType&#39;,&#39;Ticket&#39;, &#39;FirstName&#39;, &#39;SecondName&#39;] num_cols = [x for x in feature_cols if x not in cat_cols] print(len(feature_cols), len(cat_cols), len(num_cols)) . df[num_cols].describe() . plt.figure(figsize=(16, 16)) for i, col in enumerate(num_cols): ax = plt.subplot(4, 2, i + 1) ax.set_title(col) df[col].hist(bins=50) . Feature Transformation . Apply log2(1 + x) transformation followed by standardization for count variables to make them close to the normal distribution. log2(1 + x) has better resolution than log1p and it preserves the values of 0 and 1. . for col in [&#39;SameFirstName&#39;, &#39;SameSecondName&#39;, &#39;Fare&#39;, &#39;FamilySize&#39;, &#39;Parch&#39;, &#39;SibSp&#39;]: df[col] = np.log2(1 + df[col]) df.describe() . scaler = StandardScaler() df[num_cols] = scaler.fit_transform(df[num_cols]) . Label-encode categorical variables using kaggler.preprocessing.LabelEncoder, which creates new categories for NaNs as well as rare categories (using the threshold of min_obs). . lbe = LabelEncoder(min_obs=50) df[cat_cols] = lbe.fit_transform(df[cat_cols]).astype(int) . AutoEncoder using Keras . Basic stacked autoencoder. I will add the versions with DAE and emphasized DAE later. . encoding_dim = 64 def get_model(encoding_dim, dropout=.2): num_dim = len(num_cols) num_input = keras.layers.Input((num_dim,), name=&#39;num_input&#39;) cat_inputs = [] cat_embs = [] emb_dims = 0 for col in cat_cols: cat_input = keras.layers.Input((1,), name=f&#39;{col}_input&#39;) emb_dim = max(8, int(np.log2(1 + df[col].nunique()) * 4)) cat_emb = keras.layers.Embedding(input_dim=df[col].max() + 1, output_dim=emb_dim)(cat_input) cat_emb = keras.layers.Dropout(dropout)(cat_emb) cat_emb = keras.layers.Reshape((emb_dim,))(cat_emb) cat_inputs.append(cat_input) cat_embs.append(cat_emb) emb_dims += emb_dim merged_inputs = keras.layers.Concatenate()([num_input] + cat_embs) encoded = keras.layers.Dense(encoding_dim * 3, activation=&#39;relu&#39;)(merged_inputs) encoded = keras.layers.Dropout(dropout)(encoded) encoded = keras.layers.Dense(encoding_dim * 2, activation=&#39;relu&#39;)(encoded) encoded = keras.layers.Dropout(dropout)(encoded) encoded = keras.layers.Dense(encoding_dim, activation=&#39;relu&#39;)(encoded) decoded = keras.layers.Dense(encoding_dim * 2, activation=&#39;relu&#39;)(encoded) decoded = keras.layers.Dropout(dropout)(decoded) decoded = keras.layers.Dense(encoding_dim * 3, activation=&#39;relu&#39;)(decoded) decoded = keras.layers.Dropout(dropout)(decoded) decoded = keras.layers.Dense(num_dim + emb_dims, activation=&#39;linear&#39;)(decoded) encoder = keras.Model([num_input] + cat_inputs, encoded) ae = keras.Model([num_input] + cat_inputs, decoded) ae.add_loss(keras.losses.mean_squared_error(merged_inputs, decoded)) ae.compile(optimizer=&#39;adam&#39;) return ae, encoder . ae, encoder = get_model(encoding_dim) ae.summary() . inputs = [df[num_cols].values] + [df[x].values for x in cat_cols] ae.fit(inputs, inputs, epochs=100, batch_size=16384, shuffle=True, validation_split=.2) . encoding = encoder.predict(inputs) print(encoding.shape) np.savetxt(feature_file, encoding, fmt=&#39;%.6f&#39;, delimiter=&#39;,&#39;) . Model Training + Feature Selection + Hyperparameter Optimization . Train the LightGBM model with pseudo label and 5-fold CV. In the first fold, perform feature selection and hyperparameter optimization using kaggler.model.AutoLGB. . seed = 42 n_fold = 5 X = pd.concat((df[feature_cols], pd.DataFrame(encoding, columns=[f&#39;enc_{x}&#39; for x in range(encoding_dim)])), axis=1) y = df[target_col] X_tst = X.iloc[n_trn:] cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed) p = np.zeros_like(y, dtype=float) p_tst = np.zeros((tst.shape[0],)) for i, (i_trn, i_val) in enumerate(cv.split(X, y)): if i == 0: clf = AutoLGB(objective=&#39;binary&#39;, metric=&#39;auc&#39;, random_state=seed) clf.tune(X.iloc[i_trn], y[i_trn]) features = clf.features params = clf.params n_best = clf.n_best print(f&#39;{n_best}&#39;) print(f&#39;{params}&#39;) print(f&#39;{features}&#39;) trn_data = lgb.Dataset(X.iloc[i_trn], y[i_trn]) val_data = lgb.Dataset(X.iloc[i_val], y[i_val]) clf = lgb.train(params, trn_data, n_best, val_data, verbose_eval=100) p[i_val] = clf.predict(X.iloc[i_val]) p_tst += clf.predict(X_tst) / n_fold print(f&#39;CV #{i + 1} AUC: {roc_auc_score(y[i_val], p[i_val]):.6f}&#39;) np.savetxt(predict_val_file, p, fmt=&#39;%.6f&#39;) np.savetxt(predict_tst_file, p_tst, fmt=&#39;%.6f&#39;) . print(f&#39; CV AUC: {roc_auc_score(y, p):.6f}&#39;) print(f&#39;Test AUC: {roc_auc_score(pseudo_label[target_col], p_tst)}&#39;) . Submission File . n_pos = int(0.34911 * tst.shape[0]) th = sorted(p_tst, reverse=True)[n_pos] print(th) confusion_matrix(pseudo_label[target_col], (p_tst &gt; th).astype(int)) . sub[target_col] = (p_tst &gt; th).astype(int) sub.to_csv(submission_file) . If you find it helpful, please upvote the notebook and give a star to Kaggler. If you have questions and/or feature requests for Kaggler, please post them as Issue in the Kaggler GitHub repository. . Happy Kaggling! .",
            "url": "kaggler.com/notebook/kaggle/2021/04/18/autoencoder-pseudo-label-autolgb.html",
            "relUrl": "/notebook/kaggle/2021/04/18/autoencoder-pseudo-label-autolgb.html",
            "date": " • Apr 18, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Kaggler Pipeline",
            "content": "Kaggler Pipeline for Data Science Competitions . In this blog, we are going to go over the fundementals of the Kaggler repository, a machine learning pipeline for data science competitions. The Kaggler pipeline uses Makefiles and Python scripts to coordinate dependencies, and allows quick iteration of new features and models. You can watch the demo at Kaggler TV Episode #4. . The pipeline is driven by running a model training, such as logistic regression, using the corresponding Makefile, e.g., $make -f Makefile.logreg1. Before going into the details of a model run, let’s build our data and features from bottom up. To start, we need to initialize our repo by going to the Kaggler repository and clicking use this template to name and create our repository, e.g., cat-in-the-dat-ii. Next, clone the repository by . $git clone https://github.com/YOUR_GITHUB_ID/cat-in-the-dat-ii.git $cd cat-in-the-dat-ii . Data . The file Makefile defines the directories and the structure of the pipeline. . # XXX: competition name COMPETITION := cat-in-the-dat-ii # gsed on macOS. sed on LINUX SED := gsed # directories DIR_DATA := input DIR_BUILD := build DIR_FEATURE := $(DIR_BUILD)/feature DIR_METRIC := $(DIR_BUILD)/metric DIR_MODEL := $(DIR_BUILD)/model # directories for the cross validation and ensembling DIR_VAL := $(DIR_BUILD)/val DIR_TST := $(DIR_BUILD)/tst DIR_SUB := $(DIR_BUILD)/sub DIRS := $(DIR_DATA) $(DIR_BUILD) $(DIR_FEATURE) $(DIR_METRIC) $(DIR_MODEL) $(DIR_VAL) $(DIR_TST) $(DIR_SUB) # data files for training and predict DATA_TRN := $(DIR_DATA)/train.csv DATA_TST := $(DIR_DATA)/test.csv SAMPLE_SUBMISSION := $(DIR_DATA)/sample_submission.csv LABEL_IDX = 25 ID_TST := $(DIR_DATA)/id.tst.csv HEADER := $(DIR_DATA)/header.csv Y_TRN:= $(DIR_FEATURE)/y.trn.txt Y_TST:= $(DIR_FEATURE)/y.tst.txt data: $(DATA_TRN) $(DATA_TST) $(SAMPLE_SUBMISSION) $(DIRS): mkdir -p $@ $(DATA_TRN) $(DATA_TST) $(SAMPLE_SUBMISSION): | $(DIR_DATA) kaggle competitions download -c $(COMPETITION) -p $(DIR_DATA) find . -name &quot;*.zip&quot; -exec sh -c &#39;unzip -d `dirname {}` {}&#39; &#39;;&#39; $(HEADER): $(SAMPLE_SUBMISSION) head -1 $&lt; &gt; $@ $(ID_TST): $(SAMPLE_SUBMISSION) cut -d, -f1 $&lt; | tail -n +2 &gt; $@ $(Y_TST): $(SAMPLE_SUBMISSION) | $(DIR_FEATURE) cut -d, -f2 $&lt; | tail -n +2 &gt; $@ $(Y_TRN): $(DATA_TRN) | $(DIR_FEATURE) cut -d, -f$(LABEL_IDX) $&lt; | tail -n +2 &gt; $@ # cleanup clean:: find . -name &#39;*.pyc&#39; -delete clobber: clean -rm -rf $(DIR_DATA) $(DIR_BUILD) .PHONY: clean clobber mac.setup ubuntu.setup apt.setup pip.setup . First, we need to define the name of the competition in Makefile. After that, running $make data will download the specified competition data from Kaggle into the ./input directory. You need to install the Kaggle API, and accept the competition rules on Kaggle to be able to download the data. If you do not download the data manually at this time, the pipeline will automatically start the download when running the first model training. The parameters defined in Makefile are as follows. . $DIR_DATA is the directory for the input data. . $DIR_TRN, $DIR_TST, and $SAMPLE_SUBMISSION are the downloaded train, test and sample submission files. . LABEL_IDX is the column index of the target variable in the train file, and needs to be specified. . $Y_TRN is the file containing the target labels, and it is created automatically by the pipeline. . $HEADER and $ID_TST are also created by the pipeline, and are used to build submission files. . Feature Engineering . Let’s create our first feature by one hot encoding all the categorical columns 1. All the columns in this competition are categorical. The feature engieering for a specific feature are defined in files ./src/generate_$FEATURE_NAME.py, e.g., ./src/generate_e1.py. We also need to create a makefile correponding to this feature, Makefile.feature.e1 as follows. . #-- # e1: all OHE&#39;d features #-- include Makefile FEATURE_NAME := e1 FEATURE_TRN := $(DIR_FEATURE)/$(FEATURE_NAME).trn.sps FEATURE_TST := $(DIR_FEATURE)/$(FEATURE_NAME).tst.sps FEATURE_MAP := $(DIR_FEATURE)/$(FEATURE_NAME).fmap $(FEATURE_TRN) $(FEATURE_TST) $(FEATURE_MAP): $(DATA_TRN) $(DATA_TST) | $(DIR_FEATURE) python ./src/generate_$(FEATURE_NAME).py --train-file $&lt; --test-file $(lastword $^) --train-feature-file $(FEATURE_TRN) --test-feature-file $(FEATURE_TST) --feature-map-file $(FEATURE_MAP) . Feature makefiles include all the parameters from Makefile. The parameters defined in Makefile.feature.e1 are . FEATURE_NAME: specified name of the feature . FEATURE_TRN, FEATURE_TST: train and test feature files, which are the outputs created by ./src/generate_$(FEATURE_NAME).py. . FEATURE_MAP: a file where we keep the name of the features, which is also created by ./src/generate_$(FEATURE_NAME).py. . Cross-Validation and Test Predictions . The models are defined in makefiles Makefile.$ALGO_NAME, e.g., Makefile.logreg1. At the top of each model file, we define which feature is going to be included as shown below. Then, we give the algorithm a short name, ALGO_NAME, for reference. We define the parameters for the algorithm, C, REGULARIZER, CLASS_WEIGHT and SOLVER in this case. We also specifiy a model name for reference, MODEL_NAME. The cross validation for algorithms are run by files ./src/train_predict_$MODEL_NAME.py, e.g., ./src/train_predict_logreg1.py, which produce validation and test predictions, PREDICT_VAL and PREDICT_TST. . After the cross validation, ./src/evaluate.py evaluates the validation predictions for a given metric, and writes the score to the file METRIC_VAL. Finally the submission file, SUBMISSION_TST, is created using the test predictions. . include Makefile.feature.e1 ALGO_NAME := logreg C := 1.0 REGULARIZER := l2 CLASS_WEIGHT := balanced SOLVER := lbfgs MODEL_NAME := $(FEATURE_NAME)_$(ALGO_NAME)_$(REGULARIZER)_$(C) METRIC_VAL := $(DIR_METRIC)/$(MODEL_NAME).val.txt PREDICT_VAL := $(DIR_VAL)/$(MODEL_NAME).val.yht PREDICT_TST := $(DIR_TST)/$(MODEL_NAME).tst.yht SUBMISSION_TST := $(DIR_SUB)/$(MODEL_NAME)_sub.csv all: validation submission validation: $(METRIC_VAL) submission: $(SUBMISSION_TST) retrain: clean_$(ALGO_NAME) submission submit: $(SUBMISSION_TST) kaggle competitions submit -c $(COMPETITION) -f $&lt; -m $(MODEL_NAME) $(PREDICT_TST) $(PREDICT_VAL): $(FEATURE_TRN) $(FEATURE_TST) | $(DIR_VAL) $(DIR_TST) python ./src/train_predict_logreg1.py --train-feature-file $&lt; --test-feature-file $(word 2, $^) --predict-valid-file $(PREDICT_VAL) --predict-test-file $(PREDICT_TST) --C $(C) --regularizer $(REGULARIZER) --class_weight $(CLASS_WEIGHT) --solver $(SOLVER) --retrain $(METRIC_VAL): $(PREDICT_VAL) $(Y_TRN) | $(DIR_METRIC) python ./src/evaluate.py --predict-file $&lt; --target-file $(lastword $^) &gt; $@ cat $@ $(SUBMISSION_TST): $(PREDICT_TST) $(HEADER) $(ID_TST) | $(DIR_SUB) paste -d, $(lastword $^) $&lt; &gt; $@.tmp cat $(word 2, $^) $@.tmp &gt; $@ rm $@.tmp .DEFAULT_GOAL := all . If we would like to run the same model with a different feature, e.g., j1, all we need to do is to change the first line in Makefile.logreg1 to include Makefile.feature.j1. The pipeline will automatically create this feature and run cross validation using ./src/train_predict_j1.py. . Similarly, if we would like to run cross-validation using a different model, such as LightGBM, we need to include the right feature in Makefile.lgb1, and run $make -f Makefile.lgb1. If the train and test features for are already created, they will not be created again. . Ensemble . After creating several features and model runs, running the ensemble model is similar to running a single model. Ensemble model uses the predictions from single model runs as features. All we need to do is specify which model predictions should be included in the ensemble in Makefile.feature.esb1 as base models. The feature names should be the same as the model names defined in the model makefiles. . Submit . Final step is to submit our predictions. Kaggler pipeline allows submitting predictions through CLI. You need to have the following lines in your model makefile, as in Makefile.lgb1 . submit: $(SUBMISSION_TST) kaggle competitions submit -c $(COMPETITION) -f $&lt; -m $(MODEL_NAME) . To make a submission with the predictions from this model and feature, all you need to do is type the following. The submission will inculde MODEL_NAME as a message for the submission. . $make -f Makefile.lgb1 submit . Conclusion . We covered the main components of the Kaggler repository. Hopefully, this blog helps you become more comfortable with the Kaggler pipeline. Happy Kaggling :) . References . Kaggler repository: https://github.com/kaggler-tv/kaggler-template . | Kaggler-TV Episode 4: https://www.youtube.com/watch?v=861NAO5-XJo&amp;feature=youtu.be . | Official Kaggle_API: https://github.com/Kaggle/kaggle-api . | Kaggler template for cat-in-the-dat-ii: https://github.com/kaggler-tv/cat-in-the-dat-ii . | https://www.kaggle.com/cuijamm/simple-onehot-logisticregression-score-0-80801 . | https://www.kaggle.com/cuijamm/simple-onehot-logisticregression-score-0-80801 &#8617; . |",
            "url": "kaggler.com/2020/02/19/kaggler-pipeline.html",
            "relUrl": "/2020/02/19/kaggler-pipeline.html",
            "date": " • Feb 19, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Kaggler 0 8",
            "content": "Kaggler 0.8.0 Release . Kaggler 0.8.0 is released. It added model.BaseAutoML and model.AutoLGB for automatic feature selection and hyper-parameter tuning using hyperopt. . The implementation is based on the solution of the team AvengersEnsmbl at the KDD Cup 2019 Auto ML track. Details and winners’ solutions at the competition are available at the competition website. . model.BaseAutoML is the base class, from which you can inherit to implement your own auto ML class. model.AutoLGB is the auto ML class for LightGBM. It’s simple to use as follows: . from kaggler.model import AutoLGB model = AutoLGB(objective=&#39;binary&#39;, metric=&#39;auc&#39;) model.tune(X_trn, y_trn) model.fit(X_trn, y_trn) p = model.predict(X_tst) . Other updates include: . Add .travis.yml for Travis CI | Add tests with pytest | Use flake8 linting | Fix the macOS installation issue (#34) | For more details, please check out the documentation and repository. | . Any comments or contributions will be appreciated. .",
            "url": "kaggler.com/2019/08/03/kaggler-0-8.html",
            "relUrl": "/2019/08/03/kaggler-0-8.html",
            "date": " • Aug 3, 2019"
        }
        
    
  
    
        ,"post9": {
            "title": "Layoff My Story",
            "content": "Layoff – My Story . Update: I was not affected by the layoff in the news. I’m sharing about the one I had a while ago. I don’t need a new opportunity for now. Thanks for asking. 🙂 . . . It was one of less ideal days at work. . While getting ready for work, I received an email announcing the layoff of over 400 people in marketing. . At work, a series of follow-up meetings got scheduled. I talked to my team, who didn’t get affected, to address any concerns. . Later in the afternoon, farewell emails began to arrive. I replied to some, wished the best, and connected to them on LinkedIn. . It surely hurts when it happens. Either to me or to my colleagues. . . I was laid off in 2001. It was just 9 months after I started my first full time job when the company shut down my department. I was confused, angry and felt like a failure, then I cried. . Looking back, I am thankful for the experience. . It opened up better opportunities. With the previous work experience, the job search was much easier. I had better understanding of what I could offer, and which companies needed it. In the end, I landed at a company with a greater fit. . It helped me have the right mindset at work. At the new company, I grew so much and so fast because I was humbled and grateful for the new opportunity every day. . It also gave me a better perspective on my career. Since then, no matter how I like my job, I keep reminding myself that “this won’t be my last company“. Employment can change, but relationship, skills and experiences will last. It’s wise to focus on what will last. . . If it happens again, it will still hurt, but I won’t feel the same confusion, anger or failure. I won’t cry. 🙂 . I hope all my colleagues keep their heads up, get stronger and wiser, and find better opportunities. . Best wishes for their career and families. .",
            "url": "kaggler.com/2019/07/30/layoff-my-story.html",
            "relUrl": "/2019/07/30/layoff-my-story.html",
            "date": " • Jul 30, 2019"
        }
        
    
  
    
        ,"post10": {
            "title": "Neurips 2017 Notes",
            "content": "NeurIPS 2017 Notes . by Hang Li . Jeong and I attended NeurIPS 2017 in December, 2017. Our notes are as follows. . NeurIPS 2017 Notes | Take-Aways for Professionals | Technical Trends | Detailed Session-by-Session Notes On 12/4 (Mon) TUTORIALS | OPENING REMARKS/ INVITED TALK | POSTER SESSIONS | | On 12/5 (Tue) INVITED TALK | POSTER SESSIONS | | On 12/6 (Wed) INVITED TALK | POSTER SESSIONS | | On 12/7 (Thu) INVITED TALK | SYMPOSIUM – INTERPRETABLE ML | | | Other Resources | Take-Aways for Professionals . As shown in the statistics shared by organizers during opening remarks, the majority of NeurIPS papers are from academia. Even papers from industry, which are only a small fraction, are mostly from research organizations. What can professionals take away from this academic conference? In my experience, people from industry can get following benefits from NeurIPS. . Cutting-edge research: This might not be applicable in practice immediately, but can still provide important perspectives and directions on each problem. | Recruiting: I would say that 90% of sponsors are focus on hiring. All big companies had their after-parties (a.k.a. recruiting events). | Networking: For some people, this is the most important benefit at NeurIPS. With over 7,000 attendees, NeurIPS 2017 was the largest academic conference in Machine Learning. Everyday I enjoyed conversations with many people in the same field at the poster sessions, after-parties, and even on the way back home with uberpool. | . . Technical Trends . We noticed technical trends as follows. . Meta-learning | Interpretability | ML systems (or systems for ML) | Bayesian modeling | Unsupervised learning | Probabilistic programming | . Below are areas that I would like to investigate further in 2018. . Model Interpretation | Attention models | Online learning | Reinforcement learning | . Detailed Session-by-Session Notes . Below are more detailed notes: . On 12/4 (Mon) . TUTORIALS . Title Comments . Deep Learning: Practice and Trends | Very good summary of deep learning’s current status and trends. CNN, RNN, adversarial networks and unsupervised domain adaptation are closer to actual application. These models should be in professionals’ tool boxes. Meta learning and graph networks are interesting but further away from application. | . Deep Probabilistic Modeling with Gaussian Processes | This talk brings an important point. In real world applications, we need to know not only pointwise predictions, but also the level of uncertainty in predictions to support decision making. | . Geometric Deep Learning on Graphs and Manifolds by Michael Bronstein | This talk focuses on a interesting trend in deep learning, which uses deep learning on graphs data. In my opinion, there is still a long way to have real applications out of this field. | . OPENING REMARKS/ INVITED TALK . | Title | Comments | | ————- | ————- | | Opening Remarks &amp; Powering the next 100 years | Opening remarks has several interesting statistics of NeurIPS. It shows that NeurIPS is a very academia-centric conference. The invited talk, explains the huge amount of energy human need and the limitation of fossil fuel and low-carbon tech. Some ideas of how machine learning can help new energy (fusion) next 100 years and have big impact. Including: exploration and inference experiments data. Adding human (domain experts) preferences into ML approach. Mentioned several Bayesian approaches. It is about applied machine learning in physics which can impact world a lot. Thanks to many open source frameworks, it gets much easier to apply ML to different problem. ML becomes a major tool and will have huge impact across different domains. | . POSTER SESSIONS . Title Comments . SvCCa: Singular vector Canonical Correlation analysis for Deep understanding and improvement | Google’s blog and paper to understand deep learning models. It can be used to improve prediction performance. The key idea is using Singular vector Canonical Correlation (SvCC) to analysis hidden layer parameters. | . Dropoutnet: addressing Cold Start in recommender Systems | This focuses only on the item cold start. It need a metadata based vector representative of new items. | . LightGBM: A Highly Efficient Gradient Boosting Decision Tree | This paper explains the implementation of LightGBM. It uses different approximate approach from XGBoost’s. | . Discovering Potential Correlations via Hypercontractivity | An interesting idea to find potential relationship in the subset of data. | . Other interesting papers | Learning Hierarchical Information Flow with Recurrent Neural Modules. Learning ReLUs via Gradient Descent. Clone MCMC: Parallel High-Dimensional Gaussian Gibbs Sampling Efficient Use of Limited-Memory Accelerators for Linear Learning on Heterogeneous Systems | . On 12/5 (Tue) . INVITED TALK . Title Comments . Why AI Will Make it Possible to Reprogram the Human Genome | This is one of the most impactful areas of AI/DL. Lately, AI/DL has been used to tackle many challenges in healthcare and shown some promising results. | . Test Of Time Award: Random Features for Large-Scale Kernel Machines | This is the spotlight talk of NeurIPS 2017. It stirred a lot of discussions online. I highly recommend that you watch the video. Points from both sides of discussion are valid. Some related discussions: Yann LeCun’s rebuttal to Ali’s talk Alchemy, Rigour and Engineering | . The Trouble with Bias | This is a good topic. Data collection and creation process can introduce strong undesirable bias to the data set. ML algorithms can reproduce and even reinforce such bias. This is more than a technical problem. | . POSTER SESSIONS . Title Comments . A Unified Approach to Interpreting Model Predictions | Use expectations and Shapley values to interpret model prediction. Unified several previous approaches including LIME. https://github.com/slundberg/shap | . Positive-Unlabeled Learning with Non-Negative Risk Estimator | 1 class classification is very useful in real world, e.g. click ads, watch content, etc. This paper use a different loss function in PU learning. | . An Applied Algorithmic Foundation for Hierarchical Clustering | There are several papers on hierarchical clustering. This is just one of them. Hierarchical clustering is also very useful in real world. In this paper it more focus on the foundation(objective function) of this problem. | . Affinity Clustering: Hierarchical Clustering at Scale | Another hierarchical clustering paper. A bottom-up hierarchical clustering. Each time make many merge decisions. | . Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results | This is an interesting semi-supervised deep learning approach. I feel it used students to prevent overfitting. Teacher and student improve each other in a virtuous cycle. | . Unbiased estimates for linear regression via volume sampling | Choose samples wisely can get similar (not bad) performance w entire data set. This will be useful in the scenarios which is costly to get labels. | . A framework for Multi-A(rmed)/B(andit) Testing with Online FDR Control | There are several papers of MAB(Multi-armed bandit), this is one of them. MAB can be very useful in website optimization. | . Other interesting papers | Streaming Weak Submodularity: Interpreting Neural Networks on the Fly. Generalization Properties of Learning with Random Features | . On 12/6 (Wed) . INVITED TALK . Title Comments . The Unreasonable Effectiveness of Structure | This talk discussed the structure in input and output. Then describe a way to describe “structure” in data. (Probabilistic Soft Logic http://psl.linqs.org/ ) | . Deep Learning for Robotics | If working in robotics domain, this is a must attend talk. This talk discussed many unsolved pieces to the AI robotics puzzle and how DL (deep reinforcement learning, meta learning, etc ) can help. Some ideas might be useful in other domain. | . POSTER SESSIONS . Title Comments . Clustering with Noisy Queries | This paper describe and analysis a way of how to gather answers of a clustering problem. Instead of asking “do element u belong to cluster A” this paper suggest asking “do elements u and v belong to the same cluster?” | . End-to-End Differentiable Proving | Very interesting paper which try to combine NN and 1st order logic expert system. Learn vector representation of symbols. | . ELF: An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games | Looks like a fun place to try AI(:)). | . Attention Is All You Need | A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. | . Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles | Measure the uncertainty is very important. This paper describe a way (simple non-Bayesian baseline) to measure uncertainty. | . Other interesting papers | Train longer, generalize better: closing the generalization gap in large batch training of neural networks. Unsupervised Image-to-Image Translation Networks. A simple neural network module for relational reasoning. Style Transfer from Non-parallel Text by Cross-Alignment | . On 12/7 (Thu) . INVITED TALK . Title Comments . Learning State Representations | This is a very interesting talk. It tried to peel the onions of how human make decision and learn stuff. The researcher also design experiments to prove the hypothesis of “we cluster experiences together into task states based on similarity and learning happens within a cluster, not across cluster borders”. Then try to design model structure to represent this cluster(state). | . On Bayesian Deep Learning and Deep Bayesian Learning | This talk is about combine Bayesian Learning and Deep Learning. This topic can be very useful in the future. It also include several projects in this area. | . SYMPOSIUM – INTERPRETABLE ML . Title Comments . About this symposium | I think interpretability is a very important part of models. As be mentioned in one talk of this symposium interpretability is not a purely computational problem and beyond tech. The final goal still be untangle(understand) causal impact, model interpretability can be valuable in at least 2 aspects: debug model predict, help generate hypotheses to do controlled experiment. | . Invited talk - The role of causality for interpretability. | This talk discussed how to use causality in model interpretability. | . Invited talk - Interpretable Discovery in Large Image Data Sets | This talk present a DEMUD(SVOD-based plus explanations) method to interprete image data sets. | . Poster | Detecting Bias in Black-Box Models Using Transparent Model Distillation. The Intriguing Properties of Model Explanations. Feature importance scores and lossless feature pruning using Banzhaf power indices | . Debate about whether or not interpretability is necessary for machine learning | Interesting debates about interpretability. Worth to watch. | . Other Resources . NeurIPS videos, slides and notes are available as follows. . NeurIPS 2017 Proceedings | Slides | Videos https://www.youtube.com/results?search_query=NeurIPS+2017 | https://nips.cc/Conferences/2017/Videos | . | Curated Resources https://github.com/kihosuh/nips_2017 | https://github.com/hindupuravinash/nips2017 | . | Notes NeurIPS 2017 – Day 1 Highlights by Emmanuel Ameisen | NeurIPS 2017 – Day 2 Highlights by Emmanuel Ameisen | NeurIPS 2017 – Day 3 Highlights by Emmanuel Ameisen | Highlights from My First NeurIPS by Ryan Rosario | NeurIPS 2017 Notes by David Abel (pdf) | NeurIPS 2017 Reports by Viktoriya Krakovna | NeurIPS 2017 notes and thoughts by Olga Liakhovich | . | .",
            "url": "kaggler.com/2018/02/05/neurips-2017-notes.html",
            "relUrl": "/2018/02/05/neurips-2017-notes.html",
            "date": " • Feb 5, 2018"
        }
        
    
  
    
        ,"post11": {
            "title": "2nd Place Solution Cikm 2017",
            "content": "Second Place Solution at CIKM AnalytiCup 2017 – Lazada Product Title Quality Challenge . by Tam Nguyen . Lazada Product Title Quality Challenge . In this challenge, the participants were provided with a set of product titles, description, and attributes, together with the associated title quality scores (clarity and conciseness) as labeled by Lazada internal QC team. The task is to build a product title quality model that can automatically grade the clarity and the conciseness of a product title. . Team members . Tam T. Nguyen, Kaggle Grandmaster, Postdoctoral Research Fellow at Ryerson University | Hossein Fani, PhD Student at University of New Brunswick | Ebrahim Bagheri, Associate Professor at Ryerson University | Gilberto Titericz, Kaggle Grandmaster ( #1 Kaggler), Data Scientist at AirBnb | . Solution Overview . We present our winning approach for the Lazada Product Title Quality Challenge for the CIKM Cup 2017 where the data set was annotated as conciseness and clarity by Lazada QC team. . The participants were asked to build machine learning model to predict conciseness and clarity of an SKU based on product title, short description, product categories, price, country, and product type. As sellers could freely enter anything for title and description, they might contain typos or misspelling words. Moreover, there were many annotators labelling the data so there must be disagreement on the true label of an SKU. This makes the problem difficult to solve if one is solely using traditional natural language processing and machine learning techniques. . In our proposed approach, we adapted text mining and machine learning methods which take into account both feature and label noises. Specifically, we are using bagging methods to deal with label noise where the whole training data cannot be used to build our models. Moreover, we think that for each SKU, conciseness and clarity would be annotated by the same QC. It means that conciseness and clarity should be correlated in a certain manner. Therefore, we extended our bagging approach by considering out of fold leakage to take advantage of co-relation information. . Our proposed approach achieved the root mean squared error (RMSE) of 0.3294 and 0.2417 on the test data for conciseness and clarity, respectively. You may refer to the paper or source code for more details. .",
            "url": "kaggler.com/2017/12/05/2nd-place-solution-cikm-2017.html",
            "relUrl": "/2017/12/05/2nd-place-solution-cikm-2017.html",
            "date": " • Dec 5, 2017"
        }
        
    
  
    
        ,"post12": {
            "title": "Winners Solution Porto Seguro",
            "content": "Winner’s Solution at Porto Seguro’s Safe Driver Prediction Competition . by Jeong-Yoon Lee . Winner’s Solution at Porto Seguro’s Safe Driver Prediction Competition | Feature Engineering | Local Validation | Normalization | Unsupervised Learning | Learning with Train+Test Features Unsupervised | Other Unsupervised Models | Neural Nets | LightGBM | XGBoost | Blending | Software Used | Hardware Used | Total Time Spent | What Did Not Work | The Porto Seguro Safe Driver Prediction competition at Kaggle finished 2 days ago. 5,170 teams with 5,798 people competed for 2 months to predict if a driver will file an insurance claim next year with anonymized data. . Michael Jahrer, Netflix Grand Prize winner and Kaggle Grandmaster, took the lead from the beginning and finished #1. He graciously shared his solution right after the competition. Let’s check out his secret sauce. (This was initially posted on the Kaggle forum and reposted here with minor format changes with permission from him.) . . Thanks to Porto Seguro to provide us with such a nice, leakage-free, time-free and statistical correct dataset. . A nice playground to test the performance of everything, this competition was stat similar to Otto, like larger testset than train, anonymous data, but differ in details. . I wanna dive straight into solution. . It’s a blend of 6 models. 1x lightgbm, 5x nn. All on same features, I just removed *calc and added 1-hot on *cat. All neural nets are trained on denoising autoencoder hidden activation, they did a great job in learning a better representation of the numeric data. lightgbm on raw data. Nonlinear stacking failed, simple averaging works best (all weights=1). . That’s the final 0.2965 solution. 2 single models would have been enough to win (#1 + #2 give me 0.29502 on private). . The complete list of models in the final blend: . . Font is a bit small, you need to increase the zoom with ctrl (+). . The difference to my private .2969 score is I added bagging versions nBag=32 of the above mentioned 6 models, all weight=1, and Igor’s 287 script with weight=0.05. Was not really worth the effort for .2965 -&gt; .2969 gain huh!? I selected these 2 blends at the end. . Feature Engineering . I dislike this part most, my creativity is too low for an average competition lifetime, also luck plays huge role here. Therefore I like representation learning, its also an step towards AI. . Basically I removed calc, added 1-hot to *cat features. That’s all I’ve done. No missing value replacement or something. This is feature set “f0” in the table. This ends up in exactly 221 dense features. With single precision floats its 1.3GB RAM (1e-94221(595212+892816)). . Thanks to the public kernels (wheel of fortune eg.) that suggest to remove *calc features, I’m too blind and probably would not have figured this out by myself. I never remove features. . Local Validation . 5-fold CV as usual. Fixed seed. No stratification. Each model has own rand seed in CV (weight init in nn, data_random_seed in lightgbm). Test predictions are arithmetic averages of all fold models. Just standard as I would use for any other task. Somebody wrote about bagging and its improvements, I spend a week in re-training all my models in a 32-bag setup (sampling with replacement). Score only improved a little. . Normalization . Input normalization for gradient-based models such as neural nets is critical. For lightgbm/xgb it does not matter. The best what I found during the past and works straight of the box is “RankGauss”. Its based on rank transformation. First step is to assign a linspace to the sorted features from 0..1, then apply the inverse of error function ErfInv to shape them like Gaussian, then I subtract the mean. Binary features are not touched with this transformation (eg. 1-hot ones). This works usually much better than standard mean/std scaler or min/max. . Unsupervised Learning . Denoising autoencoders (DAE) are nice to find a better representation of the numeric data for later neural net supervised learning. One can use train+test features to build the DAE. The larger the testset, the better 🙂 An autoencoder tries to reconstruct the inputs features. So features = targets. Linear output layer. Minimize MSE. A denoising autoencoder tries to reconstruct the noisy version of the features. It tries to find some representation of the data to better reconstruct the clean one. . With modern GPUs we can put much computing power to solve this task by touching peak floating point performance with huge layers. Sometimes I saw over 300W power consumption by checking nvidia-smi. . So why manually constructing 2,3,4-way interactions, use target encoding, search for count features, impute features, when a model can find something similar by itself? . The critical part here is to invent the noise. In tabular datasets we cannot just flip, rotate, sheer like people are doing this in images. Adding Gaussian or uniform additive / multiplicative noise is not optimal since features have different scale or a discrete set of values that some noise just didn’t make sense. I found a noise schema called “swap noise”. Here I sample from the feature itself with a certain probability “inputSwapNoise” in the table above. 0.15 means 15% of features replaced by values from another row. . Two different topologies are used by myself. Deep stack, where the new features are the values of the activations on all hidden layers. Second, bottleneck, where one middle layer is used to grab the activations as new dataset. This DAE step usually blows the input dimensionality to 1k..10k range. . Learning with Train+Test Features Unsupervised . You might think I am cheating when using test features too for learning. So I’ve done an experiment to check the effectiveness of unsupervised learning without test features. For reference I took model #2, public:0.28970, private:0.29298. With exactly same params it ends up in a slightly weaker CV gini:0.2890. public:0.28508, private:0.29235. Private score is similar, public score is worse. So not a complete breakdown as expected. Btw total scoring time of the testset with this “clean” model is 80[s]. . Other Unsupervised Models . Yes I tried GANs (generative adversarial networks) here. No success. Since NIPS2016 I was able to code GANs by myself. A brilliant idea. Generated MNIST digits looked fine, CIFAR images not that. . For generator and discriminator I used MLPs. I think they have a fundamental problem in generating both numeric and categorical data. The discriminator won nearly all the time on my setups. I tried various tricks like truncation the generator output. Clip to known values, many architectures, learn params, noise vec length, dropout, leakyRelu etc. Basically I used activations from hidden layers of the discrimiator as new dataset. At the end they were low 0.28x on CV, too low to contribute to the blend. Haven’t tried hard enough. . Another idea that come late in my mind was a min/max. game like in GAN to generate good noise samples. Its critical to generate good noise for a DAE. I’m thinking of a generator with feature+noiseVec as input, it maximizes the distance to original sample while the autoencoder (input from generator) tried to reconstruct the sample… more maybe in another competition. . Neural Nets . Feedforward nets trained with backprop, accelerated by minibatch gradient updates. This is what all do here. I use vanilla SGD (no momentum or adam), large number of epochs, learning rate decay after every epoch. Hidden layers have ‘r’ = relu activation, output is sigmoid. Trained to minimize logloss. In bottleneck autoencoder the middle layer activation is ‘l’ = linear. When dropout!=0 it means all hidden layers have dropout. Input dropout often improve generalization when training on DAE features. Here a slight L2 regularization also helps in CV. Hidden layer size of 1000 works out of the box for most supervised tasks. All trained on GPU with 4-byte floats. . LightGBM . Nice library, very fast, sometimes better than xgboost in terms of accuracy. One model in the ensemble. I tuned params on CV. . XGBoost . I didn’t found a setup where xgboost adds something to the blend. So no used here in Porto. . Blending . Nonlinear things failed. That’s the biggest difference to the Otto competition where xgb, nn were great stackers. Every competition has its own pitfalls. Whatever. For me even tuning of linear blending weights failed. So I stick with all w=1. . Software Used . Everything I’ve done here end-to-end was written in C++/CUDA by myself. Of course I used lightgbm and xgboost C interface and a couple of acceleration libs like cuBLAS. I’m a n00b in python or R like you guys are experts. My approach is still old school and low level. I want to understand what is going from top to bottom. At some time, I’ll learn it, but currently there are just too much python/R packages that bust my head, I’m stick with loop-based code. . Hardware Used . All models above can be run on a 32GB RAM machine with clever data swapping. Next to that I use a GTX 1080 Ti card for all neural net stuff. . Total Time Spent . Some exaflops and kilowatts of GPU power was wasted for this competition for sure. Models run longer than I spend on writing code. Reading all the forum posts also costs a remarkable amount of time, but here my intention was don’t miss anything. At the end it was all worth. Big hands to all the great writers here like Tilli, CPMP, .. really great job guys. . What Did Not Work . Upsampling, deeper autoencoders, wider autoencoders, KNNs, KNN on DAE features, nonlinear stacking, some feature engineering (yes, I tried this too), PCA, bagging, factor models (but others had success with it), xgboost (other did well with that) and much much more.. . That’s it. .",
            "url": "kaggler.com/2017/12/01/winners-solution-porto-seguro.html",
            "relUrl": "/2017/12/01/winners-solution-porto-seguro.html",
            "date": " • Dec 1, 2017"
        }
        
    
  
    
        ,"post13": {
            "title": "Quora How Many Employed Ds",
            "content": "Quora: How many employed data scientists are able to solve problems from online competitions such as Kaggle’s? . by Jeong-Yoon Lee . Before reading further, please watch this video (only 1m 47s long), which shows how an average man compares to a football player at 40 yard dash. . When I talk to data science professionals, especially senior ones with more experience, I often encounter optimism on one’s competitiveness - “I know what I am doing and can build good models at work - maybe better than others”. . Online competitions provide objective measures for at least a few criteria, such as prediction accuracy, time to build a good model, reproducibility, etc. . For most data scientists, including myself, working on competitions is a reality check and humbling experience: . At the Intelligence Advanced Research Projects Activity (IARPA) tournament, the performance of “superforecasters” was 50% better than other forecasters, and 30% better than even those with access to secret data 1. | At KDD Cup 2015, the winning teams achieved over 90% accuracy while over 100 teams remained around 60% accuracy, 30% lower than the best score 2. | At Criteo Display Advertising Challenge, the benchmark solution provided by a well respected domain expert was outperformed by a simple 100+ lines of Python code written by a Kaggle user, tinrtgu. | . Long tenure doesn’t guarantee superior performance. As summarized by Dr. Ericsson in his bestseller book, Peak, the doctor, teacher, or driver with twenty years of experiences is likely to be worse than the one with only five because one’s performance deteriorates gradually with years of routine/automated work in the absence of deliberate efforts to improve. . Going back to the original question, employed data scientists “without learning from competitions” are likely to do very poorly on competitions. . The learning doesn’t need to come from participating in competitions. Out of 1MM+ Kaggle users, only 65K+ participate in competitions, while others learn cutting edge algorithms and best practices from tutorials, solutions shared by others, working on open data sets, etc. . Whenever I talk to someone who discounts the benefits of competitions without having a single competition experience, and yet is very confident on her/his modeling capability, I can’t help thinking about the average-man-vs-football-player video above, and just smile. :) . Competing against 0.1% improvement in accuracy? It’s like criticizing that Olympian 100m sprinters compete for 0.1 sec. That’s not for most of us. Don’t worry about it until you get close. We have much longer way to go. . Footnotes . Superforecasting: The Art and Science of Prediction eBook: Philip E. Tetlock, Dan Gardner: Kindle Store &#8617; . | Rank &#8617; . |",
            "url": "kaggler.com/2017/08/28/quora-how-many-employed-ds.html",
            "relUrl": "/2017/08/28/quora-how-many-employed-ds.html",
            "date": " • Aug 28, 2017"
        }
        
    
  
    
        ,"post14": {
            "title": "New Editor Tam",
            "content": "New Editor – Tam T. Nguyen, Kaggle Grandmaster . by Jeong-Yoon Lee . . I am happy to announce that we have a new editor, Tam T. Nguyen, joining Kaggler.com. . Tam is a Competition Grandmaster at Kaggle. He won the 1st prizes at KDD Cup 2015, IJCAI-15 repeat buyer competition, and Springleaf marketing response competition. . Currently, he is Postdoctoral Search Fellow at Ryerson University in Toronto, Canada. Prior to that, he was Data Analytics Project Lead at I2R A*STAR. He earned his Ph.D. in Computer Science from NTU Singapore. He’s originally from Vietnam. . Please subscribe to us at Kaggler.com, Facebook, and Twitter. .",
            "url": "kaggler.com/2017/07/15/new-editor-tam.html",
            "relUrl": "/2017/07/15/new-editor-tam.html",
            "date": " • Jul 15, 2017"
        }
        
    
  
    
        ,"post15": {
            "title": "Keras Backend Benchmark",
            "content": "Keras Backend Benchmark: Theano vs TensorFlow vs CNTK . by Jeong-Yoon Lee . Inspired by Max Woolf’s benchmark, the performance of 3 different backends (Theano, TensorFlow, and CNTK) of Keras with 4 different GPUs (K80, M60, Titan X, and 1080 Ti) across various neural network tasks are compared. . For the performance of TensorFlow and CNTK with K80, the numbers reported at Max Woolf’s benchmark are used. . Conclusion . The accuracies of Theano, TensorFlow and CNTK backends are similar across all benchmark tests, while speeds vary a lot. . Theano is significantly (up to 50 times) slower than TensorFlow and CNTK. | Between TensorFlow and CNTK, CNTK is a lot (about 2 to 4 times) faster than TensorFlow for LSTM (Bidirectional LSTM on IMDb Data and Text Generation via LSTM), while speeds for other type of neural networks are close to each other. | . Among K80, M60, Titan X and 1080 Ti GPUs: . 1080 Ti is the fastest. | K80 is the slowest. | M60 is faster than K80 and comparable to Titan X and 1080 Ti. | Theano is significantly (up to 14 times) faster on 1080 Ti than on Titan X, while the improvements for TensorFlow and CNTK are moderate. | . Detailed results are available at https://github.com/szilard/benchm-dl/blob/master/keras_backend.md .",
            "url": "kaggler.com/2017/07/12/keras-backend-benchmark.html",
            "relUrl": "/2017/07/12/keras-backend-benchmark.html",
            "date": " • Jul 12, 2017"
        }
        
    
  
    
        ,"post16": {
            "title": "Quora How To Become Kaggle Master",
            "content": "Quora: How did you become a Kaggle Master . by Jeong-Yoon Lee . Thanks Hui Jun Ng for A2A. . I can share about how to become a Kaggle Competition Master. There are 2 other kinds of Kaggle Masters: the Kernel Master and Discussion Master 1. . I wrote Jeong-Yoon Lee’s answer to What does it take to rank within #10 on Kaggle? What is an ideal learning path for a beginner in data science? What all technologies and skills does one need to acquire and in what order? How long does it take? before and it is, not surprisingly, relevant to this question as well. . At the time of writing (7/9/2017), there are about 1,000 Kagglers who are either competition Grand Masters (92) or Masters (868). . . The requirements to become a Kaggle Competition Master are: . Gold Medal: top 10 in 1 competition | Silver Medals: top 5% in 2 competitions | . Earning 2 silver medals is something that you can achieve eventually just by practicing at Kaggle consistently. As you learn from best practices shared by others on Kernels and forums at each competition, you will get closer to the top. . However, earning 1 gold medal is different. Even many (26) of top 100 Kagglers have only 1 or 2 gold medals. It requires good data science skills such as ETL, EDA, modeling, validation, and ensembles as well as other things such as creative post processing, hacks, good team work and lots of luck. :) . . To share my story, honestly I don’t remember how and when I became a Kaggle Master because I didn’t compete for it. . When I started Kaggle 6 years ago, I was fascinated by the idea of competing against other data scientists across the world. Also I was amazed by top Kagglers on how fast they came up with great solutions at ANY competitions. . I just wanted to learn from them to become a better data scientist. So I kept participating in competitions, talking to them, teaming up with them, and learning from them. . Let me rephrase what I said at Jeong-Yoon Lee’s answer to What does it take to rank within #10 on Kaggle? What is an ideal learning path for a beginner in data science? What all technologies and skills does one need to acquire and in what order? How long does it take? here: . I never thought that I would be the top 10 because there were so many Kagglers who were (and still are) much better than myself. I just enjoyed competing at Kaggle, worked on competitions regularly, teamed up with great people, and was really lucky. . If you enjoy the journey itself, whether you make the top 10 or not doesn’t really matter, but at the same time, if the chance comes, I hope you will be there ready to take it. . Enjoy! . Footnotes . Kaggle Progression System &#8617; . |",
            "url": "kaggler.com/2017/07/10/quora-how-to-become-kaggle-master.html",
            "relUrl": "/2017/07/10/quora-how-to-become-kaggle-master.html",
            "date": " • Jul 10, 2017"
        }
        
    
  
    
        ,"post17": {
            "title": "Quora What Does It Feel Like",
            "content": "Quora: What does it feel like to be addicted to Kaggle? . by Jeong-Yoon Lee . Giuliano Janson gave a great perspective as an ex-Kaggle addict who successfully recovered from it. Let me give mine as an active Kaggle addict, who is helpless without any hope for rehab. ;) . I have a weekly Data Science journal club at work, which I turned into a weekly Kaggle club. I invite people from outside the company as well and now we have about 10 people joining from 4 different companies. . Today, as we did post-mortem on the Quora competiton that ended earlier this week, one of attendees, who is relatively new to Kaggle, shared that she found it very addictive. . I agreed with her and added that it is addictive because it is so to observe yourself improving, just like how work-out and career advancement can be addictive. It is a different kind of addiction from ones that harm yourself. . At the post-mortem meeting, we shared lists of things that we learned from the competition: Feature engineering in NLP with various embeddings, good ML implementations such as LightGBM, XGBoost and Keras, new deep learning architectures combining LSTM or CNN with meta features, and many more. . And we talked about which competition to enter next. Yeah, we don’t need a break. We need another dose of a competiton, or , as I like to put, a deliberate practice opportunity. . One tip for me to remain addicted for a long time - past 6 years - is that I don’t compete to rank higher, but I compete to learn more and have fun with others. That’s why I compete with a team with different people at various skill levels, including first time Kagglers. . How do I feel? I feel great to be addicted to Kaggle and even better to be addicted to self improvement. :) . At the Quora competition, we finished 36th out of 3,307 teams. One of members was a first timer. Yeah, I gave him a pretty good gateway drug. No regret! ;) .",
            "url": "kaggler.com/2017/06/12/quora-what-does-it-feel-like.html",
            "relUrl": "/2017/06/12/quora-what-does-it-feel-like.html",
            "date": " • Jun 12, 2017"
        }
        
    
  
    
        ,"post18": {
            "title": "Build Kaggle Machine",
            "content": "Building Your Own Kaggle Machine . . In 2014, I shared the specifications of a 6-core 64GB RAM desktop system that I purchased at around USD 2,000. Since then, I added NVidia Titan X to it for deep learning at additional USD 1,000, and it served me well. . However, as other team members started joining me on data science competitions and deep learning competitions got more popular, my team decided to build a more powerful desktop system. . The specifications of the new system that we built are as follows: . CPU: Xeon 2.4GHz 14-Core | RAM: 128GB DDR4-2400 | GPU: 4 NVidia 1080 Ti 11GB | SSD: 960GB | HDD: 4TB 7200RPM | PSU: 1600W 80+ Titanium certified | . Total cost including tax and shipping was around USD 7,000. Depending on the budget, you can go down to 2 (-USD 1,520) 1080 Ti GPU cards instead of 4, or 64GB (-USD 399) instead of 128GB RAM, and still have a decent system at around USD 5,000. . You can find the full part lists here. . Additional Resources . Which GPU(s) to Get for Deep Learning by Tim Dettmers | Building a 32-Thread Xeon Monster PC for Less Than the Price of a Flagship Core i7 by TechSpot | .",
            "url": "kaggler.com/2017/04/06/build-kaggle-machine.html",
            "relUrl": "/2017/04/06/build-kaggle-machine.html",
            "date": " • Apr 6, 2017"
        }
        
    
  
    
        ,"post19": {
            "title": "Winning Data Science Competitions",
            "content": "Winning Data Science Competitions – Latest Slides . . This year I had several occasions to give my “Winning Data Science Competitions” talk – at Microsoft, KSEA-SWC 2017, USC Applied Statistics Club, Spark SC, and Whisper. . I am grateful for all these opportunities to share what I enjoy with the data scientist community. . I truly believe that working on competitions on a regular basis can make us better data scientists. Hope my talk and slides help other data scientists. . My talk is outlined as follows: . Why compete For fun | For experience | For learning | For networking | . | Data science competition intro Competitions | Structure | Kaggle | . | Misconceptions of data science competitions No ETL? | No EDA? | Not worth it? | Not for production? | . | Best practices Feature engineering | Diverse algorithms | Cross validation | Ensemble | Collaboration | . | Personal tips | Additional resources | . You can find latest slides here .",
            "url": "kaggler.com/2017/04/05/winning-data-science-competitions.html",
            "relUrl": "/2017/04/05/winning-data-science-competitions.html",
            "date": " • Apr 5, 2017"
        }
        
    
  
    
        ,"post20": {
            "title": "Kaggler 0 5 Released",
            "content": "Kaggler 0.5.0 Released . by Jeong-Yoon Lee . I am glad to announce the release of Kaggler 0.5.0. Kaggler 0.5.0 has a significant improvement in the performance of the FTRL algorithm thanks to Po-Hsien Chu (github, kaggle, linkedin). . Results . We increase the train speed by up to 100 times compare to 0.4.x. Our benchmark shows that one epoch with 1MM records with 8 features takes 1.2 seconds with 0.5.0 compared to 98 seconds with 0.4.x on an i7 CPU. . Motivation . The FTRL algorithm has been a popular algorithm since its first appearance on a paper published by Google. It is suitable for highly sparse data, so it has been widely used for click-through-rate (CTR) prediction in online advertisement. Many Kagglers use FTRL as one of their base algorithms in CTR prediction competitions. Therefore, we want to improve our FTRL implementation and benefit Kagglers who use our package. . Methods . We profile the code with cProfile and resolve the overheads one by one: . Remove over-heads of Scipy Sparse Matrix row operation: Scipy sparse matrix checks many conditions in __getitems__, resulting in a lot of function calls. In fit(), we know that we’re fetching exactly each row, and it is very unlikely to exceed the bound, so we can fetch the indexes of each row in a faster way. This enhancement makes our FTRL 10x faster. | More c-style enhancement: Specify types more clearly, return a whole list instead of yielding feature indexes, etc. These enhancements make our FTRL 5X faster when interaction==False. | Faster hash function for interaction features: The last enhancement is to remove the overhead of hashing of interaction features. We use MurMurHash3, which scikit-learn uses, to directly hash the multiplication of feature indexes. This enhancement makes our FTRL 5x faster when interaction==True. | . Contributor . Po-Hsien Chu (github, kaggle, linkedin) .",
            "url": "kaggler.com/2017/01/11/kaggler-0-5-released.html",
            "relUrl": "/2017/01/11/kaggler-0-5-released.html",
            "date": " • Jan 11, 2017"
        }
        
    
  
    
        ,"post21": {
            "title": "Ds Packages",
            "content": "Great Packages for Data Science in Python and R . by Hang Li . Domino’s Chief Data Scientist, Eduardo Ariño de la Rubia talk about Python and R as the “best” language for data scientists. A list of useful packages from this talk. . Python . Feather – Fast, interoperable binary data frame storage for Python, R, and more powered by Apache Arrow | Ibis – Productivity-centric Python data analysis framework for SQL systems and the Hadoop platform. Co-founded by the creator of pandas | Paratext – A library for reading text files over multiple cores. | Bcolz – A columnar data container that can be compressed. | Altair – Declarative statistical visualization library for Python | Bokeh – Interactive Web Plotting for Python | Blaze – NumPy and Pandas interface to Big Data | Xarry – N-D labeled arrays and datasets in Python | Dask – Versatile parallel programming with task scheduling | Keras – High-level neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. | PyMC3 – Probabilistic Programming in Python: Bayesian Modeling and Probabilistic Machine Learning with Theano | . R . Feather – Fast, interoperable binary data frame storage for Python, R, and more powered by Apache Arrow | Haven – Import foreign statistical formats into R via the embedded ReadStat C library. | readr – Read flat/tabular text files from disk (or a connection). | Jsonlite A fast JSON parser and generator optimized for statistical data and the web. | ggplot2 – A system for ‘declaratively’ creating graphics, based on “The Grammar of Graphics”. | htmlwidgets – A framework for creating HTML widgets that render in various contexts including the R console, ‘R Markdown’ documents, and ‘Shiny’ web applications. | leaflet – Create and customize interactive maps using the ‘Leaflet’ JavaScript library and the ‘htmlwidgets’ package. | tilegramsR – Provide R spatial objects representing Tilegrams. | dplyr – A fast, consistent tool for working with data frame like objects, both in memory and out of memory. | broom – Convert statistical analysis objects from R into tidy data frames | tidytext – Text mining for word processing and sentiment analysis using ‘dplyr’, ‘ggplot2’, and other tidy tools. | mxnet – The MXNet R packages brings flexible and efficient GPU computing and state-of-art deep learning to R. | tensorflow – TensorFlow™ is an open source software library for numerical computation using data flow graphs. | .",
            "url": "kaggler.com/2016/12/30/ds-packages.html",
            "relUrl": "/2016/12/30/ds-packages.html",
            "date": " • Dec 30, 2016"
        }
        
    
  
    
        ,"post22": {
            "title": "Allstate Competition",
            "content": "Solution Sharing for the Allstate Competition at Kaggle . I participated in the Allstate competition at Kaggle and finished 54th out of 3,055 teams. I shared my solution in the forum after the competition here: . . Congrats for winners and top performers, and thanks for great sharing to all contributors in the forum. It’s always a humbling experience to compete at Kaggle. I learn so much at every competition from a lot of fellow kagglers. . Here I’d like to share my code base and notes for the competition: . Code repo with competition notes | Wiki page with internal LB | . My friends and I have been using the framework based on Makefiles for competitions for years now and it has worked great so far. . Introduction to the framework is available on the TalkingData forum . Our previous code repo for past competitions are also available at: . For Bosch (#22) | For TalkingData (#37) | . Hope it’s helpful. .",
            "url": "kaggler.com/2016/12/13/allstate-competition.html",
            "relUrl": "/2016/12/13/allstate-competition.html",
            "date": " • Dec 13, 2016"
        }
        
    
  
    
        ,"post23": {
            "title": "Predictive Modeling",
            "content": "Predictive Modeling: Why the “who” is just as important as the “how” . by Jeong-Yoon Lee . There is significant debate in the data science community around the most important ingredients for attaining accurate results from predictive models. Some claim that it’s all about the quality and/or quantity of data, that you need a certain size data set (typically large) of a particular quality (typically very good) in order to get meaningful outputs. Others focus more on the models themselves, debating the merits of different single models – deep learning, gradient boosting machine, Gaussian process, etc. – versus a combined approach like the Ensemble Method. . I think that both of these positions have some truth. While it’s not as simple as “more data, better results” (see cases from Twitter and Netflix showing that the volume of data was almost meaningless to predictive accuracy), nor is the model itself the only predictor of success, all of those elements do play a role in how precise the results will be. But there is another factor that is almost always overlooked: the modelers themselves. Like the models they create, not all data scientists are created equal. I am less interested in who is “smarter” or has a better education, and more in how competitive and dedicated the modeler is. Most marketers don’t question the qualifications of a data science team because they expect that given good data and a solid algorithmic approach, they will achieve good predictive performance. At the very least, performance across different modelers should be comparable. Unfortunately, that’s not always the case. . In his New York Times bestseller Superforecasting, Prof. Philip Tetlock at University of Pennsylvania showed that, at the Intelligence Advanced Research Projects Activity (IARPA) tournament, the performance of “superforecasters” was 50% better than standard, and 30% better than those with access to secret data. This clearly demonstrates that the people doing the modeling, not the data or the models themselves, make a huge difference. . More relevant to predictive modeling specifically, KDD, one of most prestigious data science conferences, has hosted an annual predictive modeling competition, KDD Cup, since 1997. It attracts participants from top universities, companies, and industries around the world. Although every team is given exactly the same data set, and is familiar with same state-of-the-art algorithms, the resulting performances vary wildly across teams. Last year, the winning team achieved 91% accuracy while over 100 teams remained below 63% accuracy, 30% lower than the best score. . Both of these examples show the importance of not just the “how,” but the “who” when it comes to predictive modeling. This isn’t always the easiest thing for marketers to assess, but should definitely be taken into consideration when evaluating predictive analytics solutions. Ask about the data, and the models and methodology, but don’t forget the modelers themselves. The right data scientists can make all the difference to the success of your predictive program. .",
            "url": "kaggler.com/2016/08/06/predictive-modeling.html",
            "relUrl": "/2016/08/06/predictive-modeling.html",
            "date": " • Aug 6, 2016"
        }
        
    
  
    
        ,"post24": {
            "title": "Winning Data Science Competitions",
            "content": "Winning Data Science Competitions @ datascience.la . . On October 27th, I presented my favorite topic, Data Science competitions, at the DataScience.LA meetup. . Here are the slides and video. . Slides | Video | .",
            "url": "kaggler.com/2015/11/19/winning-data-science-competitions.html",
            "relUrl": "/2015/11/19/winning-data-science-competitions.html",
            "date": " • Nov 19, 2015"
        }
        
    
  
    
        ,"post25": {
            "title": "Kagglers Toolbox",
            "content": "Kaggler’s Toolbox – Setup . . I’d like to open up my toolbox that I’ve built for data mining competitions, and share with you. . Let me start with my setup. . Kaggler’s Toolbox – Setup | System | Git | S3 / Dropbox | Makefile | SSH Tunneling | tmux | System . I have access to 2 machines: . Laptop – Macbook Pro Retina 15″, OS X Yosemite, i7 2.3GHz 4 Core CPU, 16GB RAM, GeForce GT 750M 2GB, 500GB SSD | Desktop – Ubuntu 14.04, i7 5820K 3.3GHz 6 Core CPU, 64GB RAM, GeForce GT 620 1GB, 120GB SSD + 3TB HDD | . I purchased the desktop from eBay around at $2,000 a year ago (September 2014). . Git . As the code repository and version control system, I use git. . It’s useful for collaboration with other team members. It makes easy to share the code base, keep track of changes and resolve conflicts when two people change the same code. . It’s useful even when I work by myself too. It helps me reuse and improve the code from previous competitions I participated in before. . For competitions, I use gitlab instead of github because it offers unlimited number of private repositories. . S3 / Dropbox . I use S3 to share files between my machines. It is cheap – it costs me about $0.1 per month on average. . To access S3, I use AWS CLI. I also used to use s3cmd and like it. . I use Dropbox to share files between team members. . Makefile . For flow control or pipelining, I use makefiles (or GNU make). . It modularizes the long process of a data mining competition into feature extraction, single model training, and ensemble model training, and controls workflow between components. . For example, I have a top level makefile that defines the raw data file locations, folder hierarchies, and target variable. . Makefile . # directories DIR_DATA := data DIR_BUILD := build DIR_FEATURE := $(DIR_BUILD)/feature DIR_METRIC := $(DIR_BUILD)/metric DIR_MODEL := $(DIR_BUILD)/model # directories for the cross validation and ensembling DIR_VAL := $(DIR_BUILD)/val DIR_TST := $(DIR_BUILD)/tst DIRS := $(DIR_DATA) $(DIR_BUILD) $(DIR_FEATURE) $(DIR_METRIC) $(DIR_MODEL) $(DIR_VAL) $(DIR_TST) # data files for training and predict DATA_TRN := $(DIR_DATA)/train.csv DATA_TST := $(DIR_DATA)/test.csv SAMPLE_SUBMISSION := $(DIR_DATA)/sample_submission.csv ID_TST := $(DIR_DATA)/id.tst.csv HEADER := $(DIR_DATA)/header.csv CV_ID := $(DIR_DATA)/cv_id.txt Y_TRN:= $(DIR_FEATURE)/y.trn.txt Y_TST:= $(DIR_FEATURE)/y.tst.txt $(DIRS): mkdir -p $@ $(HEADER): $(SAMPLE_SUBMISSION) head -1 $&lt; &gt; $@ $(ID_TST): $(SAMPLE_SUBMISSION) cut -d, -f1 $&lt; | tail -n +2 &gt; $@ $(Y_TST): $(SAMPLE_SUBMISSION) | $(DIR_FEATURE) cut -d, -f2 $&lt; | tail -n +2 &gt; $@ $(Y_TRN) $(CV_ID): $(DATA_TRN) | $(DIR_FEATURE) python src/extract_target_cvid.py --train-file $&lt; --target-file $(Y_TRN) --cvid-file $(CV_ID) # cleanup clean:: find . -name &#39;*.pyc&#39; -delete clobber: clean -rm -rf $(DIR_DATA) $(DIR_BUILD) .PHONY: clean clobber mac.setup ubuntu.setup apt.setup pip.setup . Then, I have makefiles for features that includes the top level makefile, and defines how to generate training and test feature files in various formats (CSV, libSVM, VW, libFFM, etc.). . Makefile.feature.j3 . #-- # j3: h2 + row id #-- include Makefile FEATURE_NAME := j3 FEATURE_TRN := $(DIR_FEATURE)/$(FEATURE_NAME).trn.sps FEATURE_TST := $(DIR_FEATURE)/$(FEATURE_NAME).tst.sps $(FEATURE_TRN) $(FEATURE_TST): $(DATA_TRN) $(DATA_TST) | $(DIR_FEATURE) python ./src/generate_$(FEATURE_NAME).py --train-file $&lt; --test-file $(word 2, $^) --train-feature-file $(FEATURE_TRN) --test-feature-file $(FEATURE_TST) . Then, I have makefiles for single model training that includes a feature makefile, and defines how to train a single model and produce CV and test predictions. . Makefile.xg . include Makefile.feature.j3 N = 10000 DEPTH = 6 LRATE = 0.05 SUBCOL = 1 SUBROW = 0.8 SUBLEV = 0.5 WEIGHT = 1 N_STOP = 100 ALGO_NAME := xg_$(N)_$(DEPTH)_$(LRATE)_$(SUBCOL)_$(SUBROW)_$(SUBLEV)_$(WEIGHT)_$(N_STOP) MODEL_NAME := $(ALGO_NAME)_$(FEATURE_NAME) METRIC_VAL := $(DIR_METRIC)/$(MODEL_NAME).val.txt PREDICT_VAL := $(DIR_VAL)/$(MODEL_NAME).val.yht PREDICT_TST := $(DIR_TST)/$(MODEL_NAME).tst.yht SUBMISSION_TST := $(DIR_TST)/$(MODEL_NAME).sub.csv SUBMISSION_TST_GZ := $(DIR_TST)/$(MODEL_NAME).sub.csv.gz all: validation submission validation: $(METRIC_VAL) submission: $(SUBMISSION_TST) retrain: clean_$(ALGO_NAME) submission $(PREDICT_TST) $(PREDICT_VAL): $(FEATURE_TRN) $(FEATURE_TST) $(CV_ID) | $(DIR_VAL) $(DIR_TST) ./src/train_predict_xg.py --train-file $&lt; --test-file $(word 2, $^) --predict-valid-file $(PREDICT_VAL) --predict-test-file $(PREDICT_TST) --depth $(DEPTH) --lrate $(LRATE) --n-est $(N) --subcol $(SUBCOL) --subrow $(SUBROW) --sublev $(SUBLEV) --weight $(WEIGHT) --early-stop $(N_STOP) --cv-id $(lastword $^) $(SUBMISSION_TST_GZ): $(SUBMISSION_TST) gzip $&lt; $(SUBMISSION_TST): $(PREDICT_TST) $(HEADER) $(ID_TST) | $(DIR_TST) paste -d, $(lastword $^) $&lt; &gt; $@.tmp cat $(word 2, $^) $@.tmp &gt; $@ rm $@.tmp $(METRIC_VAL): $(PREDICT_VAL) $(Y_TRN) | $(DIR_METRIC) python ./src/evaluate.py --predict-file $&lt; --target-file $(word 2, $^) &gt; $@ cat $@ clean:: clean_$(ALGO_NAME) clean_$(ALGO_NAME): -rm $(METRIC_VAL) $(PREDICT_VAL) $(PREDICT_TST) $(SUBMISSION_TST) find . -name &#39;*.pyc&#39; -delete .DEFAULT_GOAL := all . Then, I have makefiles for ensemble features that defines which single model predictions to be included for ensemble training. . Makefile.feature.esb3 . include Makefile FEATURE_NAME := esb4 BASE_MODELS := xg_10000_6_0.05_1_0.8_0.5_1_100_h2 xg_10000_6_0.05_1_0.8_0.5_1_100_j3 keras_100_2_128_0.5_512_5_h2 keras_100_2_128_0.5_512_5_j3 PREDICTS_TRN := $(foreach m, $(BASE_MODELS), $(DIR_VAL)/$(m).val.yht) PREDICTS_TST := $(foreach m, $(BASE_MODELS), $(DIR_TST)/$(m).tst.yht) FEATURE_TRN := $(DIR_FEATURE)/$(FEATURE_NAME).trn.csv FEATURE_TST := $(DIR_FEATURE)/$(FEATURE_NAME).tst.csv %.sps: %.csv python src/csv_to_sps.py --csv-file $&lt; --sps-file $@ $(FEATURE_TRN): $(Y_TRN) $(PREDICTS_TRN) | $(DIR_FEATURE) paste -d, $^ | tr -d &#39; r&#39; &gt; $@ $(FEATURE_TST): $(Y_TST) $(PREDICTS_TST) | $(DIR_FEATURE) paste -d, $^ | tr -d &#39; r&#39; &gt; $@ clean:: clean_$(FEATURE_NAME) clean_$(FEATURE_NAME): -rm $(FEATURE_TRN) $(FEATURE_TST) . Finally, I can (re)produce the submission from XGBoost ensemble with 9 single models described in Makefile.feature.esb4 by (1) replacing include Makefile.feature.j3 in Makefile.xg with include Makefile.feature.esb4 and (2) running: . $ make -f Makefile.xg . SSH Tunneling . When I’m connected to Internet, I always ssh to the desktop for its computational resources (mainly for RAM). . I followed Julian Simioni’s tutorial to allow remote SSH connection to the desktop. It needs an additional system with a publicly accessible IP address. You can setup an AWS micro (or free tier) EC2 instance for it. . tmux . tmux allows you to keep your SSH sessions even when you get disconnected. It also let you split/add terminal screens in various ways and switch easily between those. . Documentation might look overwhelming, but all you need are: . # If there is no tmux session: $ tmux . or . # If you created a tmux session, and want to connect to it: $ tmux attach . Then to create a new pane/window and navigate in between: . Ctrl + b + “ – to split the current window horizontally. | Ctrl + b + % – to split the current window vertically. | Ctrl + b + o – to move to next pane in the current window. | Ctrl + b + c – to create a new window. | Ctrl + b + n – to move to next window. | . To close a pane/window, just type exit in the pane/window. . Hope this helps. . Next up is about machine learning tools I use. . Please share your setups and thoughts too. 🙂 .",
            "url": "kaggler.com/2015/09/21/kagglers-toolbox.html",
            "relUrl": "/2015/09/21/kagglers-toolbox.html",
            "date": " • Sep 21, 2015"
        }
        
    
  
    
        ,"post26": {
            "title": "Deloitte Competition",
            "content": "60 Day Journey of Deloitte Churn Prediction Competition . . 60 Day Journey of Deloitte Churn Prediction Competition | Competition | Result | Visualization | Closing | Competition . Last December, I teamed up with Michael once again to participate in the Deloitte Churn Prediction competition at Kaggle, where to predict which customers will leave an insurance company in the next 12 months. . It was a master competition, which is open to only master level Kagglers (top 0.2% out of 138K competitors), with $70,000 cash prizes for top 3 finishers. . Result . We managed to do well and finished in 4th place out of 37 teams in spite of that we did not have much time due to projects at work and family events (especially for Michael, who became a dad during the competition). . Although we were little short to earn the prize, it was a fun experience working together with Michael, competing with other top competitors across the world, and climbing the leaderboard day by day. . Visualization . I visualized our 60 day journey during the competition below, and here are some highlights (for us): . Day 22-35: Dived into the competition, set up the github repo and S3 for collaboration, and climbed up the leaderboard quickly. | Day 41-45: Second spurt. Dug in GBM and NN models. Michael’s baby girl was born on Day 48. | Day 53-60: Last spurt. Ensembled all models. Improved our score every day, but didn’t have time to train the best models. | . Motion Chart - Deloitte Churn Prediction Leaderboard . Once clicked the link above, it will show a motion chart where: . X-axis: Competition day. From day 0 to day 60. | Y-axis: AUC score. | Colored circle: Each team. If clicked, it shows which team it represents. | Right most legend: Competition day. You can drag up and down the number to see the chart on a specific day. | Initial positions of circles show the scores of their first submissions. | . For the chart, I reused the code using rCharts published by Tony Hirst at github: https://github.com/psychemedia (He also wrote a tutorial on his blog about creating a motion chart using rCharts). . Closing . We took a rain check on this, but will win next time! 🙂 .",
            "url": "kaggler.com/2014/01/03/deloitte-competition.html",
            "relUrl": "/2014/01/03/deloitte-competition.html",
            "date": " • Jan 3, 2014"
        }
        
    
  
    
        ,"post27": {
            "title": "Ds Career For Neuroscientist",
            "content": "Data Science Career for Neuroscientists + Tips for Kaggle Competitions . . Recently Prof. Konrad Koerding at Northwestern University asked for an advice on his Facebook for one of his Ph.D student, who studies Computational Neuroscience but wants to pursue his career in Data Science. It reminded me of the time I was looking for such opportunities, and shared my thoughts (now posted on the webpage of his lab here). I decide to post it here with a few fixes so that it can help others. . Data Science Career for Neuroscientists + Tips for Kaggle Competitions | Introduction | Tools in Data Science | Hints for Kaggle Data Mining Competitions Don’t jump into algorithms too fast. | Try different algorithms and blend. | Optimize at last. | | –— . Introduction . First, I’d like to say that Data Science is a relatively new field (like Computational Neuroscience), and you don’t need to feel bad to make the transition after your Ph.D. When I was out to the job market, I didn’t have any analytic background at all either. . I started my industrial career at one of analytic consulting companies, Opera Solutions in San Diego, where one of Nicolas‘ friends, Jacob, runs the R&amp;D team of the company. Jacob did his Ph.D under the supervision of Prof. Michael Arbib at University of Southern California in Computational Neuroscience as well. During the interview, I was tested to prove my thought process, basic knowledges in statistics and Machine Learning, and programming, which I’d practiced through out my Ph.D everyday. . So, if he has a good Machine Learning background with programming skills (I’m sure that he does, based on the fact he’s your student), he can be competent to pursue his career in Data Science. . Tools in Data Science . Back in the graduate school, I used mostly MATLAB with some SPSS and C. In the Data Science field, Python and R are most popular languages, and SQL is a kind of necessary evil. . R is similar to MATLAB except that it’s free. It is not a hardcore programming language and doesn’t take much time to learn. It comes with the latest statistical libraries and provides powerful plotting functions. There are many IDEs, which make easy to use R, but my favorite is R Studio. If you run R on the server with R Studio Server, you can access it from anywhere via your web browser, which is really cool. Although native R plotting functions are excellent by themselves, the ggplot2 library provides more eye-catching visualization. . For Python, Numpy + Scipy packages provides similar vector-matrix computation functionalities as MATLAB. For Machine Learning algorithms, you need Scikit-Learn, and for data handling, Pandas will make your life easy. For debugging and prototyping, iPython Notebook is really handy and useful. . SQL is an old technology but still widely used. Most of data are stored in the data warehouse, which can be accessed only via SQL or SQL equivalents (Oracle, Teradata, Netezza, etc.). Postgres and MySQL are powerful yet free, so it’s perfect to practice with. . Hints for Kaggle Data Mining Competitions . Fortunately, I had a chance to work with many of top competitors such as the 1st and 2nd place teams at Netflix competitions, and learn how they do at competitions. Here are some tips I found helpful. . Don’t jump into algorithms too fast. . Spend enough time to understand data. Algorithms are important, but no matter how good algorithm you use, garbage-in only leads to garbage-out. Many classification/regression algorithms assume the Gaussian distributed variables, and fail to make good predictions if you provide non-Gaussian distributed variables. So, standardization, normalization, non-linear transformation, discretization, binning are very important. . Try different algorithms and blend. . There is no universal optimal algorithm. Most of times (if not all), the winning algorithms are ensembles of many individual models with tens of different algorithms. Combining different kinds of models can improve prediction performance a lot. For individual models, I found Random Forest, Gradient Boosting Machine, Factorization Machine, Neural Network, Support Vector Machine, logistic/linear regression, Naive Bayes, and collaborative filtering are mostly useful. Gradient Boosting Machine and Factorization Machine are often the best individual models. . Optimize at last. . Each competition has a different evaluation metric, and optimizing algorithms to do the best for that metric can improve your chance to win. Two most popular metrics are RMSE and AUC (area under the ROC curve). Algorithms optimizing one metric is not the optimal for the other. Many open source algorithm implementations provide only RMSE optimization, so for AUC (or other metric) optimization, you need to implement it by yourself. .",
            "url": "kaggler.com/2013/10/07/ds-career-for-neuroscientist.html",
            "relUrl": "/2013/10/07/ds-career-for-neuroscientist.html",
            "date": " • Oct 7, 2013"
        }
        
    
  

  
  

  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "kaggler.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}